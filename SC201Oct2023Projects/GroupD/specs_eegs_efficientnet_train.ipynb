{"cells":[{"cell_type":"markdown","source":["# Imports and Setup"],"metadata":{"id":"_aFr5R1lFmiC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmLz-Chi0TAs"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset, random_split\n","import torchvision.transforms as T\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchvision import models\n","import albumentations as A\n","import os\n","import random\n","import gc\n","\n","from sklearn.model_selection import GroupKFold\n","from sklearn.model_selection import StratifiedKFold\n","\n","def clear_memory():\n","  torch.cuda.empty_cache()\n","  gc.collect()\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from google.colab import drive\n","drive.mount(\"/content/dirve\", force_remount=True)\n","\n","os.chdir(\"/content/dirve/MyDrive/Colab Notebooks/poster/specs_eegs_workspace\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"53WSoWyF_tjk"},"outputs":[],"source":["def seed_everything(seed: int):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","seed_everything(20)"]},{"cell_type":"markdown","source":["# Initiate Constants"],"metadata":{"id":"Ga8EVlBhGFQL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRJge1Xr0nt7"},"outputs":[],"source":["TRAIN_CSV = \"../train.csv\"\n","FULL_SPECTROGRAMS = \"./specs.npy\"\n","FULL_EEG = \"./eeg_specs.npy\"\n","\n","GROUP_FOLDS = 5\n","\n","LABELS = pd.read_csv(TRAIN_CSV).columns[-6:].to_list()"]},{"cell_type":"markdown","source":["# Metadata Preprocessing\n","- group by eeg_id\n","- add min/max offset of spectrogram offset seconds in each spectrogram_id\n","- take the mean of votes\n","- add total evaluator votes\n","- add kl_loss comparing to 1/6 uniform distribution"],"metadata":{"id":"fnAOYXu8GMhC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bm6iS_044jMI"},"outputs":[],"source":["# metadata preprocessing\n","train_df = pd.read_csv(TRAIN_CSV)\n","\n","LABELS = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n","KEEP_COLS = [\"spectrogram_id\", \"spectrogram_label_offset_seconds\", \"patient_id\", \"expert_consensus\"]\n","\n","\n","min_temp = train_df.groupby(\"eeg_id\")[[\"spectrogram_label_offset_seconds\"]].agg({\n","    \"spectrogram_label_offset_seconds\": \"min\"\n","    }).reset_index()\n","\n","min_temp.columns = [\"eeg_id\", \"min\"]\n","\n","max_temp = train_df.groupby(\"eeg_id\")[[\"spectrogram_label_offset_seconds\"]].agg({\n","    \"spectrogram_label_offset_seconds\": \"max\"\n","    }).reset_index()\n","\n","max_temp.columns = [\"eeg_id\", \"max\"]\n","\n","\n","temp = pd.merge(min_temp, max_temp, on=\"eeg_id\", how=\"left\")\n","\n","del min_temp, max_temp\n","\n","# group by eeg_id\n","train_df = train_df.groupby(\"eeg_id\")[KEEP_COLS + LABELS].agg(\n","    {**{m: \"first\" for m in KEEP_COLS},\n","    **{t: \"sum\" for t in LABELS}}\n","    ).reset_index()\n","\n","# count total evaluators\n","train_df[\"num_evaluators\"] = train_df[LABELS].values.sum(axis=1)\n","\n","# take mean of labels\n","train_df[LABELS] = train_df[LABELS]/train_df[LABELS].values.sum(axis=1, keepdims=True)\n","\n","# add group fold\n","gkf = GroupKFold(n_splits=GROUP_FOLDS)\n","for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, train_df[LABELS], train_df[\"patient_id\"])):\n","    train_df.loc[val_idx, \"fold\"] = int(fold+1)\n","train_df.head()\n","\n","# compute kl_loss\n","votes = train_df[LABELS].values + 1e-6\n","\n","# add kl_loss\n","train_df[\"kl_loss\"] = F.kl_div(\n","    torch.log(torch.tensor(votes)),\n","    torch.tensor([1/6]*6),\n","    reduction=\"none\"\n","    ).sum(dim=1).numpy()\n","\n","# merge\n","train_df = pd.merge(train_df, temp, on=\"eeg_id\", how=\"left\")"]},{"cell_type":"markdown","source":["# Setup GPU and Load Train Data"],"metadata":{"id":"32e-gb_0HAWg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXZlnd--CDup"},"outputs":[],"source":["# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Read in full spectrograms and eeg data\n","print(\"Reading in all spectrograms and eegs data...\")\n","full_eegs = np.load(FULL_EEG, allow_pickle=True).item()\n","full_specs = np.load(FULL_SPECTROGRAMS, allow_pickle=True).item()\n","print(\"Reading in all spectrograms and eegs data Complete!\")"]},{"cell_type":"markdown","source":["# Define Custom Dataset\n","- shape: N x 126 x 256 x 8 channels for X\n","- 0-3 channels are kaggle spectrograms, 4-7 are EEG to spectrograms\n","- data augmentation: horizontal flip with p=0.5\n"],"metadata":{"id":"uJB90FaTHJxX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"y29FR2zy3PR1"},"outputs":[],"source":["class CustomDataset(Dataset):\n","  def __init__(self, metadata, specs_dict, eegs_dict, transforms=False, mode=\"Train\"):\n","    self.metadata = metadata\n","    self.specs_dict = specs_dict\n","    self.eegs_dict = eegs_dict\n","    self.transforms = transforms\n","    self.mode = mode\n","    self.__epsilon = 1e-6\n","\n","  def __len__(self):\n","    return len(self.metadata)\n","\n","  def __getitem__(self, index):\n","    X, y = self.__create_data(index)\n","\n","    if self.transforms:\n","        X = self.__data_transformation(X)\n","\n","    # convert to tensors\n","    X = torch.tensor(X, dtype=torch.float32)\n","    y = torch.tensor(y, dtype=torch.float32)\n","\n","    return X, y\n","\n","  def __create_data(self, index):\n","    X = np.zeros((128, 256, 8), dtype=np.float32)\n","    y = np.zeros((6), dtype=np.float32)\n","    img = np.ones((128, 256), dtype=np.float32)\n","    row = self.metadata.iloc[index]\n","\n","    if self.mode == \"Train\":\n","        # offset = int((row[\"min\"] + row[\"max\"])//4)\n","        offset = int(row[\"spectrogram_label_offset_seconds\"] // 2)\n","        # convert labels to float32\n","        y = row[LABELS].values.astype(np.float32)\n","\n","    else:\n","        offset = 0\n","\n","    for i in range(4):\n","        # 100x300xi -> i: LL(0), RL(1), LP(2), RP(3)\n","        img = self.specs_dict[row[\"spectrogram_id\"]][offset:offset+300, i*100:(i+1)*100].T\n","\n","        # log transform\n","        # img = np.clip(img, np.exp(-4), np.exp(8))\n","        img = np.clip(img, np.exp(-6), np.exp(10))\n","        img = np.log(img)\n","\n","        # standardization\n","        m = np.nanmean(img.flatten())\n","        std = np.nanstd(img.flatten())\n","        img = (img - m) / (std + self.__epsilon)\n","        # img = np.nan_to_num(img, 0.0)\n","        img = np.nan_to_num(img, -1)\n","\n","        # fit into X (0-3 at dim=3)\n","        # 100x256xi\n","        # X[14: -14, :, i] = img[:, 22:-22] / 2.0\n","        X[14: -14, :, i] = img[:, 22:-22]\n","\n","    # eegs\n","    # 128x256x4 LL(4), RL(5), LP(6), RP(7)\n","    img = self.eegs_dict[row[\"eeg_id\"]]\n","    X[:, :, 4:] = img\n","\n","    return X, y\n","\n","\n","  def __data_transformation(self, x):\n","    transforms = A.Compose([A.HorizontalFlip(p=0.5)])\n","    return transforms(image=x)[\"image\"]"]},{"cell_type":"markdown","source":["# Define Transfer Learning Models\n","- with reshaping methods\n","1. reshaping from (N, 128, 256, 8) to (N, 512, 512, 3)\n","2. reshaping from (N, 128, 256, 8) to (N, 256, 256, 12)"],"metadata":{"id":"y1BS37KQIAKv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AyCHjzN3PPW"},"outputs":[],"source":["class Effnet_512(nn.Module):\n","  def __init__(self, num_classes=6, pretrained=True):\n","    super().__init__()\n","    self.model = models.efficientnet_b2(pretrained=pretrained)\n","    num_features = self.model.classifier[1].in_features\n","    self.model.classifier = torch.nn.Linear(num_features, num_classes)\n","\n","  def forward(self, x):\n","    x = self.__reshape_input(x)\n","    x = self.model(x)\n","    return x\n","\n","  def __reshape_input(self, x):\n","    \"\"\"\n","    reshape input from (N, 128, 256, 8) to (N, 512, 512, 3) and permute to (N, 3, 512, 512)\n","    \"\"\"\n","    spectrograms = [x[:, :, :, i:i+1] for i in range(4)]\n","    spectrograms = torch.cat(spectrograms, dim=1)\n","    eegs = [x[:, :, :, i:i+1] for i in range(4, 8)]\n","    eegs = torch.cat(eegs, dim=1)\n","    # now spectrograms and eegs are both Nx512x256x1\n","    x = torch.cat([spectrograms, eegs], dim=2)\n","    x = torch.cat([x, x, x], dim=3)\n","    x = x.permute(0, 3, 1, 2)\n","    return x\n","\n","class Effnet_256(nn.Module):\n","    def __init__(self, num_classes=6, pretrained=True):\n","        super().__init__()\n","        self.model = models.efficientnet_b2(pretrained=pretrained)\n","        self.model.features[0][0] = nn.Conv2d(12, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        num_features = self.model.classifier[1].in_features\n","        self.model.classifier = torch.nn.Linear(num_features, num_classes)\n","\n","    def forward(self, x):\n","        x = self.__reshape_input(x)\n","        x = self.model(x)\n","        return x\n","\n","    def __reshape_input(self, x):\n","        \"\"\"\n","        (N, 128, 256, 8) -> (N, 256, 256, 12])\n","        \"\"\"\n","        # LL + RL 256 x 256\n","        spectrograms_1 = [x[:, :, :, i:i+1] for i in range(2)]\n","        spectrograms_1 = torch.cat(spectrograms_1, dim=1)\n","\n","        # LP + RP 256 x 256\n","        spectrograms_2 = [x[:, :, :, i:i+1] for i in range(2, 4)]\n","        spectrograms_2 = torch.cat(spectrograms_2, dim=1)\n","\n","        # LL + LP 256 x 256\n","        eegs_1 = [x[:, :, :, i:i+1] for i in range(4, 6)]\n","        eegs_1 = torch.cat(eegs_1, dim=1)\n","\n","        # LP + RP 256 x 256\n","        eegs_2 = [x[:, :, :, i:i+1] for i in range(6, 8)]\n","        eegs_2 = torch.cat(eegs_2, dim=1)\n","\n","        # stack\n","        x = torch.cat([spectrograms_1, spectrograms_2, eegs_1, eegs_2], dim=3)\n","        x = torch.cat([x, x, x], dim=3)\n","\n","        # permute\n","        x = x.permute(0, 3, 1, 2)\n","        return x"]},{"cell_type":"markdown","source":["# Define Train and Val Functions"],"metadata":{"id":"Im4TUsxhIrGF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbc7SJml3POC"},"outputs":[],"source":["def train(train_loader, model, loss_function, optimizer, epoch, num_epoch, device, iteration):\n","  losses = []\n","  model.train()\n","  num_iters = 0\n","  for x, y in train_loader:\n","      x = x.to(device)\n","      y = y.to(device)\n","      scores = model(x)\n","      scores = F.log_softmax(scores, dim=1)\n","      loss = loss_function(scores, y)\n","      if num_iters % iteration == 0:\n","          print(f\"Epoch {epoch+1}/{num_epoch} at {num_iters}, Loss: {loss.item():.4f}\")\n","      losses.append(loss.item())\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      num_iters += 1\n","\n","  return np.mean(losses)\n","\n","def valid(val_loader, model, loss_function, device):\n","  model.eval()\n","  predictions_dict = {}\n","  predictions = []\n","  losses = []\n","  with torch.no_grad():\n","    for x, y in val_loader:\n","      x = x.to(device)\n","      y = y.to(device)\n","      scores = model(x)\n","      scores = F.log_softmax(scores, dim=1)\n","      loss = loss_function(scores, y)\n","      losses.append(loss.item())\n","      y_pred = F.softmax(scores, dim=1)\n","      predictions.append(y_pred.to(\"cpu\").numpy())\n","  predictions_dict[\"predictions\"] = np.concatenate(predictions)\n","  return np.mean(losses), predictions_dict"]},{"cell_type":"markdown","source":["# Define Train Model Function\n","- in order to switch models"],"metadata":{"id":"46LpFC7zIxih"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z31ZFy65i2Rs"},"outputs":[],"source":["def train_model(model_name:str, model_class, naming:str, size:int, total_votes=False):\n","\n","  BATCH_SIZE = 8\n","\n","  STAGE_ONE_EPOCH = 5\n","  STAGE_ONE_LR = 1e-4\n","\n","  STAGE_TWO_EPOCH = 3\n","  STAGE_TWO_LR = 1e-5\n","\n","  ITERATION = 100\n","\n","  for fold in range(GROUP_FOLDS):\n","    print(f\"### Fold {fold+1} Start Training...\")\n","    train_folds = train_df[train_df[\"fold\"] != fold+1]\n","    val_folds = train_df[train_df[\"fold\"] == fold+1]\n","\n","    train_dataset = CustomDataset(train_folds, full_specs, full_eegs, transforms=False, mode=\"Train\")\n","    val_dataset = CustomDataset(val_folds, full_specs, full_eegs, transforms=False, mode=\"Train\")\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    print(f\"# Train size: {len(train_loader)}\")\n","\n","    # model\n","    model = model_class()\n","    model.to(device)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=STAGE_ONE_LR)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","\n","    # train and val\n","    best_loss = np.inf\n","    for epoch in range(STAGE_ONE_EPOCH):\n","      # train\n","      avg_train_loss = train(train_loader, model, kl_loss, optimizer, epoch, STAGE_ONE_EPOCH, device, ITERATION)\n","      # val\n","      avg_val_loss, prediction_dict = valid(val_loader, model, kl_loss, device)\n","      predictions = prediction_dict[\"predictions\"]\n","\n","      if avg_val_loss < best_loss:\n","        best_loss = avg_val_loss\n","        torch.save({\"model\": model.state_dict(),\n","                    \"predictions\": predictions},\n","                   os.path.join(\"./models\", f\"{model_name}_{naming}_{size}_fold_{fold+1}_best.pth\"))\n","      clear_memory()\n","\n","\n","    # stage 2 training\n","    print(f\"### Fold {fold+1} Start Training Stage 2...\")\n","    if total_votes:\n","      train_stage2 = train_df[(train_df[\"fold\"] != fold+1) & (train_df[\"num_evaluators\"] >= 10)]\n","      val_stage2 = train_df[(train_df[\"fold\"] == fold+1) & (train_df[\"num_evaluators\"] >= 10)]\n","    else:\n","      train_stage2 = train_df[(train_df[\"fold\"] != fold+1) & (train_df[\"kl_loss\"] < 5.5)]\n","      val_stage2 = train_df[(train_df[\"fold\"] == fold+1) & (train_df[\"kl_loss\"] < 5.5)]\n","\n","    train_dataset_stage2 = CustomDataset(train_stage2, full_specs, full_eegs, transforms=False, mode=\"Train\")\n","    val_dataset_stage2 = CustomDataset(val_stage2, full_specs, full_eegs, transforms=False, mode=\"Train\")\n","\n","    train_loader_stage2 = DataLoader(train_dataset_stage2, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader_stage2 = DataLoader(val_dataset_stage2, batch_size=BATCH_SIZE, shuffle=True)\n","\n","    print(f\"# Train size: {len(train_loader_stage2)}\")\n","\n","    best_model_path = os.path.join(\"./models\", f\"{model_name}_{naming}_{size}_fold_{fold+1}_best.pth\")\n","    saved_model = torch.load(best_model_path)\n","    model.load_state_dict(saved_model[\"model\"])\n","\n","    best_loss = np.inf\n","    optimizer = optim.Adam(model.parameters(), lr=STAGE_TWO_LR)\n","    for epoch in range(STAGE_TWO_EPOCH):\n","      # train\n","      avg_train_loss = train(train_loader_stage2, model, kl_loss, optimizer, epoch, STAGE_TWO_EPOCH, device, ITERATION)\n","      # val\n","      avg_val_loss, prediction_dict = valid(val_loader, model, kl_loss, device)\n","      predictions = prediction_dict[\"predictions\"]\n","\n","      if avg_val_loss < best_loss:\n","        best_loss = avg_val_loss\n","        torch.save({\"model\": model.state_dict(),\n","                    \"predictions\": predictions},\n","                   os.path.join(\"./models\", f\"{model_name}_{naming}_{size}_fold_{fold+1}_best.pth\"))\n","      clear_memory()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohRwnl183PBX"},"outputs":[],"source":["def main():\n","  train_model(\"EfficientNet_b2\", Effnet_256, \"2stage_kl_loss\", 256, total_votes=False)\n","  train_model(\"EfficientNet_b2\", Effnet_512, \"2stage_kl_loss\", 512, total_votes=False)\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNPWJs1/cqkFmon/g7eYafV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}