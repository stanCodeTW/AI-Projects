{"cells":[{"cell_type":"markdown","metadata":{"id":"Ai12v2VXaS59"},"source":["### 00. 環境建置"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20001,"status":"ok","timestamp":1723015553754,"user":{"displayName":"C sc201mar24","userId":"09455476244381582499"},"user_tz":-480},"id":"jS-FjtwjpTKm","outputId":"c0dc9c92-b51d-490e-e440-7cb322c8ad92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/SC201LFINAL\n"]}],"source":["# Mount to Porject Folder\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)\n","FOLDERNAME = 'Colab\\ Notebooks/SC201LFINAL'\n","%cd drive/MyDrive/$FOLDERNAME"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3046,"status":"ok","timestamp":1723015557502,"user":{"displayName":"C sc201mar24","userId":"09455476244381582499"},"user_tz":-480},"id":"fv-KAO6DpblN","outputId":"f401b011-36d2-4ea5-96c9-9ad835f1d6e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ekmr8hO-pkSp"},"outputs":[],"source":["# 影片字幕存放區\n","\n","# 量產區 train          : val\n","TRAIN_DIRECTORY: str = '_train_rgb_front_clips'         # 31165\n","VAL_DIRECTORY: str = '_val_rgb_front_clips'             # 1741\n","LABEL_FILE_TRAIN = 'how2sign_realigned_train.csv'       # 31165\n","LABEL_FILE_VAL = 'how2sign_realigned_val.csv'           # 1741\n","\n","# # 量產區 val as train === val\n","# TRAIN_DIRECTORY: str = '_val_rgb_front_clips'          # 1741\n","# VAL_DIRECTORY: str = '_val_rgb_front_clips'             # 1741\n","# LABEL_FILE_TRAIN = 'how2sign_realigned_val.csv'        # 1741\n","# LABEL_FILE_VAL = 'how2sign_realigned_val.csv'           # 1741"]},{"cell_type":"markdown","metadata":{"id":"3ItolAjFbr4C"},"source":["\n","### 01.字幕 (sentence) : train.csv, val.csv'"]},{"cell_type":"markdown","metadata":{"id":"AqAxrpKRyD2n"},"source":["### 1. 資料讀取"]},{"cell_type":"markdown","metadata":{"id":"AH6bwqfUdb1N"},"source":["#### 1-1. 讀取字幕資訊"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cv8DWrXyqjOd"},"outputs":[],"source":["import pandas as pd\n","import csv\n","\n","# 讀取 LABEL_FILE :\n","\n","# training data\n","label_cap_train = pd.read_csv(LABEL_FILE_TRAIN, delimiter='\\t', quoting = csv.QUOTE_NONE, encoding = 'utf-8')\n","# label_cap_train = pd.read_csv(LABEL_FILE_TRAIN, delimiter='\\t', on_bad_lines='skip')\n","file_name_trains = label_cap_train.SENTENCE_NAME\n","file_cap_train = label_cap_train.SENTENCE\n","\n","# val data\n","label_cap_val = pd.read_csv(LABEL_FILE_VAL, delimiter='\\t', quoting = csv.QUOTE_NONE, encoding = 'utf-8')\n","# label_cap_val = pd.read_csv(LABEL_FILE_VAL, delimiter='\\t', on_bad_lines='skip')\n","file_name_vals = label_cap_val.SENTENCE_NAME\n","file_cap_val = label_cap_val.SENTENCE"]},{"cell_type":"markdown","metadata":{"id":"sR2n0kFvb_Cw"},"source":["#### 1-2. 資料前處理(preprocessing): 字幕(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Hx-clOBzcy-"},"outputs":[],"source":["# 定義: 特殊字元的替換 (patterns replacement)\n","\n","patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"','#','$','%','&','+']\n","replacements = ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '','','','','','']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urI0MHhN1JEH"},"outputs":[],"source":["# def: 資料前處理(data preproessing)\n","import re\n","\n","def preprocessing(reviews, patterns, replacements) -> list:\n","  lst = []\n","  for i in range(len(reviews)):\n","    review = reviews[i].lower()\n","    for pattern, replacement in zip(patterns, replacements):\n","      # review = review.replace(pattern, replacement)\n","      review = re.sub(re.escape(pattern), replacement, review)\n","    lst.append(review)\n","  return lst"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSSRHTSr1NHU"},"outputs":[],"source":["# output: 資料前處理(data preproessing output)\n","\n","file_cap_trains = preprocessing(file_cap_train, patterns, replacements)\n","file_cap_vals = preprocessing(file_cap_val, patterns, replacements)"]},{"cell_type":"markdown","metadata":{"id":"vJpndm4HcDvH"},"source":["#### 1-3. 定義: 資料筆數, token 最多字元數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie6m5BHf26p4"},"outputs":[],"source":["# 定義: 資料筆數, token 最多字元數\n","\n","num_train = len(file_cap_trains)\n","num_val = len(file_cap_vals)\n","longest_num_tokens = 20"]},{"cell_type":"markdown","metadata":{"id":"Tyf9drSkcHRW"},"source":["#### 1-4. 將字幕 做記號(Tokens) / 索引(Indexing) / 填充(Padding) 處理"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzbblorf4GTd"},"outputs":[],"source":["# def: 幫token加上, 索引(indexing)\n","\n","def indexing_tokens(mode='train') -> dict :\n","  indices = {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","  index = 4\n","\n","  for i in range(num_train):\n","    sentence = file_cap_trains[i]\n","    tokens = sentence.split()\n","    for token in tokens:\n","      if token not in indices:\n","        indices[token] = index\n","        index += 1\n","\n","  return indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0kAJQ6qT6ITI"},"outputs":[],"source":["# def: 幫字幕(sentence) indexing + Padding 去補足 所定義最多字元數 (longest_line_tokens)\n","\n","def get_data(indices, longest_line_tokens, mode='train') -> list:\n","\n","  sentences = []\n","  files = []\n","\n","  if mode == 'train':\n","    for i in range(num_train):\n","      one_train_data = []\n","      y = file_name_trains[i]\n","      sentence = file_cap_trains[i]\n","\n","      for token in sentence.split():\n","        one_train_data.append(indices[token])\n","        if len(one_train_data) == longest_line_tokens:\n","          break\n","\n","      while len(one_train_data) < longest_line_tokens:\n","        one_train_data.append(indices['<PAD>'])\n","      one_train_data.insert(0, indices['<SOS>'])\n","      one_train_data.append(indices['<EOS>'])\n","      sentences.append(one_train_data)\n","      files.append(y)\n","\n","  else:\n","    for i in range(num_val):\n","      one_val_data = []\n","\n","      y = file_name_vals[i]\n","      sentence = file_cap_vals[i]\n","\n","      for token in sentence.split():\n","        if token in indices:\n","          one_val_data.append(indices[token])\n","        else:\n","          one_val_data.append(indices['<UNK>'])\n","        if len(one_val_data) == longest_line_tokens:\n","          break\n","\n","      while len(one_val_data) < longest_line_tokens:\n","        one_val_data.append(indices['<PAD>'])\n","      one_val_data.insert(0, indices['<SOS>'])\n","      one_val_data.append(indices['<EOS>'])\n","      sentences.append(one_val_data)\n","      files.append(y)\n","\n","  return files, sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kuv3P6ahBQOV"},"outputs":[],"source":["# Loading Training Data & Val Data\n","indices = indexing_tokens()                                                     # {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","\n","training_files, training_sentences = get_data(indices, longest_num_tokens)\n","val_files, val_sentences = get_data(indices, longest_num_tokens, mode='val')\n","\n","# ---------------------------\n","# 備用: 以防萬一需要替換indices (like -> word_index)\n","reversed_indices = {value: key for key, value in indices.items()}             # {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>'}"]},{"cell_type":"markdown","metadata":{"id":"P-gabv3edE0R"},"source":["#### 1-6. 輸出dict = {檔案名稱:索引化字幕, ...}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIveSjiU9tZZ"},"outputs":[],"source":["# 幫 Train & val 的 indexing字幕資訊 轉tensors\n","\n","# import numpy as np\n","\n","# indexing 字幕(sentences)__ (尚未使用)\n","# train_sentences_tensor = torch.tensor(np.array(training_sentences))\n","# val_sentences_tensor = torch.tensor(np.array(val_sentences))\n","\n","# -----------\n","# 檔案名稱 (file name)__ (無法使用, 文字無法轉tensor 張量)\n","# train_tensor = torch.tensor(np.array(training_files))\n","# val_tensor = torch.tensor(np.array(val_files))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AaJKkM_9aXTX"},"outputs":[],"source":["# “P3” 將檔案, indexing字幕 裝成dict (類似 -> Vedio_sequences)\n","# {'--7E2sU6zP4_10-5-rgb_front': [ 0,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 15, 18,  4, 19, 20, 21,  2,  2,  1]}\n","\n","training_file_sentence_dict = {file: sentence for file, sentence in zip(training_files, training_sentences)}\n","val_file_sentence_dict = {file: sentence for file, sentence in zip(val_files, val_sentences)}"]},{"cell_type":"markdown","metadata":{"id":"znaxdX6wdqQY"},"source":["### 02.影像 (video): rgb_front_clips,"]},{"cell_type":"markdown","metadata":{"id":"8DtLXKypkFYP"},"source":["#### 2-1. 定義: 影像“幀數”和“尺寸大小”"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLqCnuavh7i7"},"outputs":[],"source":["# 常數區\n","IMG_SIZE: int = 112\n","MAX_FRAMES :int = 16\n","BATCH_SIZE_VIDEO: int = 2"]},{"cell_type":"markdown","metadata":{"id":"0AklNiavkOqO"},"source":["#### 2-2. 資料前處理: 影像 (影像裁切, 轉張量, #[N, torch.Size([16, 112, 112, 3]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVfpVEoedtzF"},"outputs":[],"source":["# def: 將影片 裁切成 大小為(IMG_SIZE*IMG_SIZE), 幀數為(MAX_FRAMES)\n","\n","import cv2\n","\n","def load_video_helper(cap, max_frames, resize):\n","    frames_count = 0\n","    try:\n","        while True:\n","            success, frame = cap.read()             # success: if video available\n","            if not success:\n","                break\n","            frame = cv2.resize(frame, resize)       # frame reszie\n","            frames_count += 1\n","            yield frame\n","            if frames_count == max_frames:\n","                break\n","    finally:\n","        cap.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DieuaOBuidQC"},"outputs":[],"source":["# def: 下載影片,並根據需求裁切 (F x H x W x C)\n","\n","def load_video(path, max_frames=MAX_FRAMES, resize=(IMG_SIZE, IMG_SIZE)):\n","    cap = cv2.VideoCapture(path)\n","\n","    #initialize variables\n","    frames = list(load_video_helper(cap, max_frames=max_frames, resize=resize))\n","    can_use = (len(frames) == max_frames)             # True or False\n","    if can_use:\n","        return can_use, np.array(frames) / 255        # /255 : normalize\n","\n","    shape = (max_frames, *resize, 3)                  # 3 = RBG\n","                                                      # max(16, (112, 112), 3) => ((128, ))\n","\n","    return can_use, np.empty(shape)"]},{"cell_type":"code","source":["def process_batch(batch_files, batch_labels):\n","    results = list(map(load_video, batch_files, (MAX_FRAMES,) * len(batch_files), ((IMG_SIZE, IMG_SIZE),) * len(batch_files)))\n","    can_use_mask, batch_data = zip(*results)\n","\n","    # Filter out only the valid video data and labels\n","    valid_data = np.array(batch_data)[np.array(can_use_mask)]\n","    valid_labels = np.array(batch_labels)[np.array(can_use_mask)]\n","\n","    return valid_data, valid_labels"],"metadata":{"id":"9soepShAEDdi"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EFLph5djqaC"},"outputs":[],"source":["# 資料前處理(影像) + 資料裝填 {影像, 字幕}\n","\n","import time\n","import os\n","import numpy as np\n","from concurrent.futures import ProcessPoolExecutor\n","from typing import *\n","\n","def prepare_data(directory: str, file_sentence_dict, shuffle=True, seed=42) -> List[Tuple[np.ndarray, int]]:\n","    start = time.time()\n","    # ****************************\n","\n","    # # 定義 list 裝填影像資料夾,\n","    files = []          # 手語影片.mp4\n","    file_names = []     # 手語影片 檔案名稱\n","\n","    # # 爬過每部手語影片.mp4 files\n","    for root, dirs, filenames in os.walk(directory):\n","        for file in filenames:\n","            if file.endswith('.mp4'):\n","                files.append(os.path.join(root, file))              # ['train_pre_rgb_front_clips/_2FBDaOPYig_1-3-rgb_front.mp4', 'train_pre_rgb_front_clips/fE6xxSbjVV8_3-8-rgb_front.mp4']\n","                file_names.append(os.path.splitext(file)[0])        # ['_2FBDaOPYig_1-3-rgb_front', 'fE6xxSbjVV8_3-8-rgb_front']\n","\n","    files = np.array(files)                                         # files.shape = (31165,) or (1741,)\n","\n","    # 標籤 true_labels\n","    true_labels = np.array([file_sentence_dict.get(name, -1) for name in file_names])\n","\n","    # # Load video data (file -> video data)\n","    # with ProcessPoolExecutor() as executor:\n","    #     results = list(executor.map(load_video, files, (MAX_FRAMES,)*len(files), ((IMG_SIZE,IMG_SIZE),)*len(files)))        # [files, (Bool , array(??? ,IMG_SIZE ,IMG_SIZE, 3)]\n","\n","    # can_use_mask, video_data = list(zip(*results))\n","    # can_use_mask = np.array(can_use_mask)\n","    # video_data = np.array(video_data)\n","\n","    # video_data = video_data[can_use_mask, :, :, :, :]\n","    # true_labels = true_labels[can_use_mask]\n","\n","    # ======================================== 2024-08-07 ========================================\n","\n","    video_data = []\n","    video_labels_filtered = []\n","\n","    batch_size = 200  # Adjust as needed based on memory constraints\n","    for i in range(0, len(files), batch_size):\n","        batch_files = files[i:i + batch_size]\n","        batch_labels = true_labels[i:i + batch_size]  # Ensure the batch labels match the batch files\n","        batch_data, batch_labels = process_batch(batch_files, batch_labels)\n","        video_data.append(batch_data)\n","        video_labels_filtered.append(batch_labels)\n","\n","    video_data = np.concatenate(video_data, axis=0)\n","    true_labels = np.concatenate(video_labels_filtered, axis=0)\n","\n","    # ======================================== 2024-08-07 ========================================\n","\n","    if shuffle:\n","        np.random.seed(seed)\n","        size = len(true_labels)\n","        # random_nums = np.random.rand(size)\n","        # sort_idx = np.argsort(random_nums)\n","        # video_data = video_data[sort_idx, :, :, :, :]\n","        # true_labels = true_labels[sort_idx]\n","        indices = np.arange(size)\n","        np.random.shuffle(indices)\n","        video_data = video_data[indices]\n","        true_labels = true_labels[indices]\n","\n","    # # Convert to PyTorch tensors\n","    # video_data = torch.tensor(np.array(video_data))\n","    # true_labels = torch.tensor(np.array(true_labels))\n","    video_data = torch.tensor(video_data, dtype=torch.float32)\n","    true_labels = torch.tensor(true_labels, dtype=torch.long)\n","\n","    result = list(zip(video_data, true_labels))       # [(data[0], true_lables[0]), (data[1], true_lables[1], ....)]\n","\n","    # 影像裁切資訊 video_data.shape =>  torch.Size([16, 112, 112, 3]\n","    # 影像字幕 true_labels.shape => torch.Size([22])\n","\n","    # ****************************\n","    end = time.time()\n","    print(f'This function took {end-start} second to complete.')\n","\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"fU05dPAznau5"},"source":["### 03.訓練資料(Train data) & 驗證資料(val data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_PmX10JVNvU"},"outputs":[],"source":["# 定義樣本常數\n","BATCH_SIZE: int = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_m_xHXp4nlKA"},"outputs":[],"source":["# Load train_data and val_data\n","\n","train_data = prepare_data(TRAIN_DIRECTORY, training_file_sentence_dict)\n","# print(f'Number of training samples: {len(train_data)}')\n","\n","val_data = prepare_data(VAL_DIRECTORY, val_file_sentence_dict)\n","# print(f'Number of validation samples: {len(val_data)}')\n","\n","# dict (like -> Vedio_sequences)\n","\n","# [(tensor(影像資訊[16, 112, 112, 3]), tensor(影片字幕indeing_01)), (tensor(影像資訊[16, 112, 112, 3]), tensor(影片字幕indeing_02)) ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQgUZ9esP5R_"},"outputs":[],"source":["# 製作 mini_train, mini_val (根據BATCH_SIZE, 使用DataLoader對train data抽樣)\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# # ---\n","# train_videos = np.array([item[0] for item in train_data])\n","# train_labels = np.array([item[1] for item in train_data])\n","# train_dataset = TensorDataset(torch.tensor(train_videos).float(), torch.tensor(train_labels).long())\n","# # ---\n","\n","mini_trains = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n","mini_vals = DataLoader(val_data, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1723015929062,"user":{"displayName":"C sc201mar24","userId":"09455476244381582499"},"user_tz":-480},"id":"UxtIuKjoQVBx","outputId":"6e981401-b339-4220-b306-3cab59c0322c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[D_train.shape] torch.Size([32, 16, 112, 112, 3])\n"]}],"source":["# check torch size\n","\n","print('[D_train.shape]', next(iter(mini_trains))[0].shape)"]},{"cell_type":"markdown","metadata":{"id":"n5QtGlAQecmT"},"source":["### 04. 模型建立"]},{"cell_type":"markdown","metadata":{"id":"AgUDWjaBexQE"},"source":["#### 4-1. 定義: 模型常數"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCygFIlifFcB"},"outputs":[],"source":["# 定義模型常數\n","\n","LONGEST_NUM_TOKENS: int = longest_num_tokens   # 每句話的長度 (20)\n","EMBEDDING_DIM: int = 300\n","\n","HIDDEN_DIM: int = 256          # hidden_size\n","VOCAB_SIZE = len(indices)      # 15983, 不重複字數\n","OUTPUT_DIM = len(indices)      # 15983, 不重複字數 = VOCAB_SIZE\n","\n","NUM_EPOCHS: int = 500\n","PRINT_EVERY_EPOCH: int = 400\n","TEACHER_FORCING_RATIO = 1.0\n","\n","# 4608 = 512*3*3"]},{"cell_type":"markdown","metadata":{"id":"a1_4FTkJiSdV"},"source":["#### 4.1.1.Pretrained word_embedding_stack_pt by Glove300"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29294,"status":"ok","timestamp":1723015958352,"user":{"displayName":"C sc201mar24","userId":"09455476244381582499"},"user_tz":-480},"id":"A3jrG-U2g9_Y","outputId":"c0b5f8b9-5eac-4a9a-9ece-aebea1fcd740"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3238, 300])\n"]}],"source":["# 利用Glove300製作embedding_stack_pt 給模型使用 (將indices索引表 拿給 Glove300 一起pretrained)\n","\n","# 下載並讀取 GloVe 300d 文件\n","def load_glove_embeddings(file_path):\n","    embeddings_index = {}\n","    with open(file_path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.split()\n","            word = values[0]\n","            coefs = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = coefs\n","    return embeddings_index\n","\n","# 創建嵌入矩陣\n","def create_embedding_matrix(word_index, embeddings_index, embedding_dim):\n","    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n","    for word, i in word_index.items():\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector\n","    return embedding_matrix\n","\n","# 初始化嵌入層\n","def init_embedding_layer(embedding_matrix):\n","    embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)\n","    return embedding_layer\n","\n","# 路徑到 GloVe 300d 文件\n","glove_file_path = 'glove.6B.300d.txt'\n","\n","# 加載 GloVe 嵌入\n","embeddings_index = load_glove_embeddings(glove_file_path)\n","\n","# 創建嵌入矩陣\n","embedding_dim = EMBEDDING_DIM\n","embedding_stack_pt_0 = create_embedding_matrix(indices, embeddings_index, embedding_dim)\n","\n","# indices = indexing_tokens()                                                     # {'<SOS>': 0, '<EOS>': 1, '<PAD>': 2, '<UNK>': 3}\n","\n","# 將嵌入矩陣轉換為 PyTorch tensor\n","embedding_stack_pt = torch.FloatTensor(embedding_stack_pt_0)\n","\n","# 打印嵌入層的尺寸\n","print(embedding_stack_pt.size())"]},{"cell_type":"markdown","metadata":{"id":"vgDf118fV6h9"},"source":["#### 4-2. 模型建立"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rE35bagThlu2"},"outputs":[],"source":["# 建立模型\n","\n","import torch\n","from torch import nn\n","import torchvision.models as models\n","from torchvision.models import ResNet50_Weights\n","\n","class VideoTextModel(nn.Module):\n","    def __init__(self, embedding_stack, embedding_dim, vocab_size, teacher_forcing_ratio = 0.5):\n","        super(VideoTextModel, self).__init__()\n","\n","        # -- video (Encoder)\n","        # ResNet\n","        # resnet = models.resnet50(pretrained=True) # UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","        resnet = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n","        self.resnet = nn.Sequential(*list(resnet.children())[:-2])    # Remove the last fully connected layer\n","        self.resnet_avgpool = nn.AdaptiveAvgPool2d((1,1))\n","\n","        # LSTM for video features (wihtout fc), Ensure input_size matches ResNet50's output = 2048\n","        self.lstm_video = nn.LSTM(input_size=2048, hidden_size=256, batch_first=True, num_layers=2, bidirectional=True)\n","\n","        # -- text (decoder)\n","        # Embedding layer for text\n","        self.embedding = nn.Embedding.from_pretrained(embedding_stack, freeze=False)\n","\n","        # LSTM for text features\n","        self.lstm_text = nn.LSTM(input_size=embedding_dim, hidden_size=256, batch_first=True, num_layers=2, bidirectional=True)\n","\n","        # Fully connected layer for classification\n","        self.fc = nn.Linear(256*2, vocab_size)\n","\n","        self._initialize_weights()\n","\n","        # teacher forcing ratio\n","        self.teacher_forcing_ratio = teacher_forcing_ratio\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.LSTM):\n","                for name, param in m.named_parameters():\n","                    if 'weight' in name:\n","                        nn.init.xavier_uniform_(param)\n","                    elif 'bias' in name:\n","                        nn.init.constant_(param, 0)\n","\n","    def forward(self, x_video, sentence):\n","\n","        # --- video\n","        # feature extraction (x_video.shape = [32, 16, 112, 112, 3])\n","        batch_size, frames, height, width, channels = x_video.size()\n","        x_video = x_video.view(batch_size*frames, channels, height, width)\n","\n","        # Resnet\n","        cnn_features = self.resnet(x_video)\n","        cnn_features = self.resnet_avgpool(cnn_features)\n","        cnn_features = cnn_features.view(batch_size, frames, -1) # torch.Size([2, 16, 512])\n","\n","        # -- encoder LSTM for video features\n","        # lstm for cnn_features torch.Size([2, 16, 512*3*3]), (h_n, c_n) will be input with decoder_input\n","        lstm_output, (h_n, c_n) = self.lstm_video(cnn_features)\n","\n","        # --- sentence\n","        # Remove second dimension, queeze sentence.shape from [1:1:20:300] to [1:20:300]\n","        sentence = sentence.squeeze(1) # sentence.squeeze(1).shape: torch.Size([batch_size, 22])\n","\n","        # word embeddings\n","        embeddings = self.embedding(sentence)  # embeddings.shape : torch.Size([batch_size, 22, embedding_dim])\n","\n","        # -- decoder\n","        decoder_outputs = []\n","        decoder_input = embeddings[:,0,:].unsqueeze(1) # decoder_input.shape: torch.Size([batch_size, 1, embedding_dim])\n","\n","        # -- teacher forcing\n","        use_teacher_forcing = True if torch.rand(1).item() < self.teacher_forcing_ratio else False\n","\n","        for t in range(sentence.size(1)):\n","            lstm_text_output, (h_n, c_n) = self.lstm_text(decoder_input, (h_n, c_n)) # decoder output\n","\n","            output = self.fc(lstm_text_output.squeeze(1)) # [batch_size, vocal_size]\n","            decoder_outputs.append(output)\n","\n","            if use_teacher_forcing:\n","              decoder_input = embeddings[:,t,:].unsqueeze(1) # decoder input without teacher forcing\n","            else:\n","              decoder_input = self.embedding(output.argmax(1)).unsqueeze(1) # next decoder input\n","\n","        decoder_outputs = torch.stack(decoder_outputs, dim=1)\n","\n","        return decoder_outputs"]},{"cell_type":"markdown","metadata":{"id":"nv1xGpNLcNQi"},"source":["### 5. 訓練 Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YaLoEdRocJSu"},"outputs":[],"source":["# 建立訓練方法\n","\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","\n","def train(model, optimizer, mini_trains, device):\n","    start = time.time()\n","    # ****************************\n","\n","    model.train()\n","    total_loss = 0\n","\n","    for epoch in range(NUM_EPOCHS):\n","        cost = 0\n","        for batch_idx, (videos, sentences) in enumerate(mini_trains):\n","\n","            # to(device)\n","            videos = videos.float().to(device)\n","            sentences = sentences.long().to(device)   # if data type != int/long, alter train data\n","\n","            # 產出 outputs\n","            outputs = model(videos, sentences)\n","\n","            # 取得 probabilities\n","            probabilities = nn.functional.log_softmax(outputs, dim = -1)\n","            # 取得最高的機率\n","            predicted_indices = torch.argmax(probabilities, dim = -1)\n","            # 生成預測字句\n","            predicted_words = [reversed_indices[idx.item()] for idx in predicted_indices[0]]\n","\n","            # Flatten\n","            sentence_flatten = torch.flatten(sentences, end_dim=-1)\n","            probabilities_flatten = torch.flatten(probabilities, end_dim=1)\n","\n","            ### sentences     torch.Size([32, 22])       ###\n","            ### probabilities torch.Size([32, 22, 3237]) ###\n","            ### output        torch.Size([32, 22, 3237]) ###\n","\n","            # 計算 loss\n","            loss = loss_function(probabilities_flatten, sentence_flatten)\n","\n","            # clear previous gradient:\n","            optimizer.zero_grad()\n","\n","            # 計算 loss / cost per epoch\n","            total_loss += loss.item()\n","            cost += loss.item()\n","\n","            # Backward propagation/\n","            loss.backward()\n","\n","            # update parameters\n","            optimizer.step()\n","\n","        if epoch % 10 == 0:\n","            print(f'Epoch: {epoch}, Cost: {cost / len(mini_trains)}')\n","            # 印出預測字句\n","            print(f\"'predicted_words: ' {predicted_words}\")\n","\n","    avg_loss = total_loss / len(mini_trains)\n","    print(f'Triaining loss: ', avg_loss)\n","\n","    # ****************************\n","    end = time.time()\n","    print(f'This function took {end-start} second to complete.')"]},{"cell_type":"markdown","metadata":{"id":"n6PiaVLNoWGh"},"source":["### 5.1 訓練開始"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YHM_1FrhNIU","outputId":"a35c8518-f187-4db7-b412-fb8692b11654","executionInfo":{"status":"ok","timestamp":1723021312832,"user_tz":-480,"elapsed":2262257,"user":{"displayName":"C sc201mar24","userId":"09455476244381582499"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["詞向量的形狀 torch.Size([3238, 300])\n","輸入層大小: 300\n","詞彙表大小: 3237\n","是否有用到 GPU: cuda\n","Teacher Forcing Ratio: 1.0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 224MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0, Cost: 4.880536295749523\n","'predicted_words: ' ['<SOS>', 'so', 'you', 'to', 'to', '<PAD>', 'to', '<PAD>', 'to', 'to', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n","Epoch: 10, Cost: 2.813847855285362\n","'predicted_words: ' ['<SOS>', 'so', 'i', 'you', 'way', 'thing', 'is', 'the', 'hair', 'of', 'of', 'can', 'to', 'out', 'and', 'the', 'back', 'of', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 20, Cost: 1.9080039880893849\n","'predicted_words: ' ['<SOS>', 'so', 'lot', 'is', 'is', 'going', 'that', 'little', 'recording', 'you', 'a', 'little', 'input', 'or', 'the', 'little', 'inch', 'length', 'depending', 'on', 'the', '<EOS>']\n","Epoch: 30, Cost: 1.1922600975743047\n","'predicted_words: ' ['<SOS>', 'and', 'then', 'you', 'a', 'lot', 'of', 'people', 'strength', 'involved', 'to', 'stabilize', 'the', 'dumbbell', 'right', 'above', 'his', 'hips', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 40, Cost: 0.7486818002329932\n","'predicted_words: ' ['<SOS>', 'so', 'way', 'that', 'dogs', 'your', 'youre', 'walking', 'your', 'youll', 'see', 'their', 'ears', 'perk', 'up', 'thats', 'their', 'ears', 'perk', 'up', 'thats', '<EOS>']\n","Epoch: 50, Cost: 0.4863429919437126\n","'predicted_words: ' ['<SOS>', 'and', 'the', 'drink', 'that', 'we', 'are', 'about', 'to', 'make', 'is', 'a', 'claridge', 'and', 'tan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 60, Cost: 0.40157250176977227\n","'predicted_words: ' ['<SOS>', 'and', 'so', 'all', 'the', 'way', 'around', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 70, Cost: 0.37060420822214196\n","'predicted_words: ' ['<SOS>', 'you', 'will', 'tend', 'to', 'crack', 'once', 'they', 'get', 'bent', 'into', 'funky', 'shapes', 'that', 'you', 'might', 'put', 'them', 'into', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 80, Cost: 0.30735083752208286\n","'predicted_words: ' ['<SOS>', 'so', 'is', 'get', 'the', 'total', 'continuation', 'of', 'processing', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 90, Cost: 0.26053740332523984\n","'predicted_words: ' ['<SOS>', 'and', 'then', 'you', 'panic', 'they', 'fly', 'and', 'they', 'dont', 'come', 'back', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 100, Cost: 0.24649728807034316\n","'predicted_words: ' ['<SOS>', 'im', 'want', 'are', 'trying', 'to', 'sell', 'a', 'straight', 'a', 'flush', 'a', 'straight', 'flush', 'or', 'a', 'royal', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 110, Cost: 0.1936754995474109\n","'predicted_words: ' ['<SOS>', 'so', 'now', 'were', 'second', 'one', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 120, Cost: 0.18000018569054427\n","'predicted_words: ' ['<SOS>', 'this', 'going', 'to', 'draw', 'the', 'sleeves', 'coming', 'into', 'his', 'side', 'like', 'that', 'and', 'as', 'you', 'draw', 'his', 'robe', 'coming', 'down', '<EOS>']\n","Epoch: 130, Cost: 0.13470111994279754\n","'predicted_words: ' ['<SOS>', 'all', 'is', 'looks', 'a', 'little', 'too', 'blue', 'here', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 140, Cost: 0.12631407863012067\n","'predicted_words: ' ['<SOS>', 'so', 'as', 'are', 'currently', 'heating', 'up', 'the', 'oil', 'and', 'at', 'this', 'point', 'you', 'are', 'going', 'to', 'want', 'to', 'be', 'very', '<EOS>']\n","Epoch: 150, Cost: 0.10343824920279009\n","'predicted_words: ' ['<SOS>', 'i', 'want', 'it', 'lifted', 'chest', 'open', 'and', 'reverse', 'fly', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 160, Cost: 0.09299944203208994\n","'predicted_words: ' ['<SOS>', 'a', 'dont', 'contrasting', 'just', 'so', 'that', 'the', 'design', 'actually', 'sticks', 'out', 'and', 'stands', 'better', 'and', 'so', 'that', 'it', 'is', 'more', '<EOS>']\n","Epoch: 170, Cost: 0.10058602297471629\n","'predicted_words: ' ['<SOS>', 'and', 'that', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 180, Cost: 0.09875057444528297\n","'predicted_words: ' ['<SOS>', 'and', 'really', 'good', 'way', 'to', 'lose', 'weight', 'sometimes', 'is', 'a', 'support', 'group', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 190, Cost: 0.06434394246726124\n","'predicted_words: ' ['<SOS>', 'so', 'to', 'be', 'real', 'important', 'to', 'know', 'what', 'time', 'period', 'because', 'people', 'acted', 'differently', 'the', 'social', 'norms', 'were', 'different', 'in', '<EOS>']\n","Epoch: 200, Cost: 0.06181249250140455\n","'predicted_words: ' ['<SOS>', 'its', 'this', 'words', 'theres', 'no', 'way', 'that', 'any', 'kind', 'of', 'oil', 'and', 'or', 'internal', 'petroleums', 'or', 'lubricants', 'can', 'contact', 'the', '<EOS>']\n","Epoch: 210, Cost: 0.05099620645934785\n","'predicted_words: ' ['<SOS>', 'so', 'attitude', 'which', 'comes', 'through', 'in', 'your', 'tone', 'of', 'voice', 'and', 'this', 'is', 'what', 'you', 'have', 'to', 'work', 'with', '<PAD>', '<EOS>']\n","Epoch: 220, Cost: 0.035911429604446446\n","'predicted_words: ' ['<SOS>', 'this', 'bought', 'this', 'at', 'the', 'store', 'and', 'there', 'appears', 'to', 'be', 'a', 'great', 'deal', 'of', 'moisture', 'in', 'the', 'actual', 'fat', '<EOS>']\n","Epoch: 230, Cost: 0.048372924983225485\n","'predicted_words: ' ['<SOS>', 'and', 'whenever', 'are', 'take', 'this', 'loosen', 'it', 'and', 'were', 'going', 'to', 'tighten', 'that', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 240, Cost: 0.04554639751505521\n","'predicted_words: ' ['<SOS>', 'you', 'let', 'be', 'your', 'knees', 'bent', 'your', 'feet', 'spread', 'out', 'moving', 'side', 'to', 'side', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 250, Cost: 0.03737746494718724\n","'predicted_words: ' ['<SOS>', 'thats', 'right', 'then', 'kimchi', 'is', 'pretty', 'all', 'mixed', 'up', 'now', 'and', 'when', 'you', 'are', 'doing', 'this', 'at', 'home', 'you', 'can', '<EOS>']\n","Epoch: 260, Cost: 0.036926960607093794\n","'predicted_words: ' ['<SOS>', 'and', 'i', 'also', 'got', 'a', 'cheap', 'brush', 'and', 'im', 'just', 'going', 'to', 'kinda', 'dry-brush', 'it', 'a', 'little', 'bit', 'onto', 'the', '<EOS>']\n","Epoch: 270, Cost: 0.034477665071824086\n","'predicted_words: ' ['<SOS>', 'some', 'im', 'youre', 'going', 'to', 'go', 'opposite', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 280, Cost: 0.037924258762763605\n","'predicted_words: ' ['<SOS>', 'it', 'really', 'definitely', 'recommend', 'getting', 'this', 'kind', 'of', 'yogurt', 'so', 'so', 'good', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 290, Cost: 0.05562413516626866\n","'predicted_words: ' ['<SOS>', 'and', 'a', 'very', 'cycle', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 300, Cost: 0.043571291456895846\n","'predicted_words: ' ['<SOS>', 'the', 'the', 'hand', 'drawn', 'diagram', 'you', 'can', 'then', 'come', 'up', 'with', 'a', 'custom', 'layout', 'depending', 'on', 'what', 'spacing', 'you', 'want', '<EOS>']\n","Epoch: 310, Cost: 0.03685198198245079\n","'predicted_words: ' ['<SOS>', 'now', 'it', 'only', 'hired', 'as', 'an', 'actor', 'on', 'miami', 'vice', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 320, Cost: 0.026847824057633127\n","'predicted_words: ' ['<SOS>', 'you', 'going', 'gipson', 'and', 'im', 'going', 'to', 'talk', 'to', 'you', 'about', 'trouble', 'shooting', 'your', 'refrigerator', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 330, Cost: 0.038540585052773906\n","'predicted_words: ' ['<SOS>', 'im', 'dont', 'to', 'lock', 'extensions', 'because', 'its', 'not', 'damaging', 'to', 'your', 'hair', 'at', 'all', 'because', 'you', 'can', 'add', 'color', 'without', '<EOS>']\n","Epoch: 340, Cost: 0.03011842232404484\n","'predicted_words: ' ['<SOS>', 'you', 'phone', 'you', 'throw', 'your', 'reverse', 'move', 'you', 'always', 'close', 'the', 'gap', 'on', 'your', 'opponent', 'come', 'in', 'engage', 'and', 'then', '<EOS>']\n","Epoch: 350, Cost: 0.0458870871613423\n","'predicted_words: ' ['<SOS>', 'so', 'best', 'point', 'line', 'is', 'actually', 'a', 'talked', 'about', 'it', 'earlier', 'is', 'nineteen', 'point', 'nine', 'for', 'college', 'and', 'high', 'school', '<EOS>']\n","Epoch: 360, Cost: 0.019305207551008573\n","'predicted_words: ' ['<SOS>', 'ill', 'wind', 'first', 'get', 'on', 'the', 'table', 'like', 'this', 'and', 'then', 'we', 'have', 'them', 'swing', 'their', 'legs', 'onto', 'the', 'table', '<EOS>']\n","Epoch: 370, Cost: 0.01684806921036431\n","'predicted_words: ' ['<SOS>', 'and', 'of', 'all', 'you', 'put', 'a', 'pot', 'of', 'water', 'on', 'to', 'boil', 'just', 'like', 'you', 'would', 'if', 'youre', 'having', 'a', '<EOS>']\n","Epoch: 380, Cost: 0.01622545808398475\n","'predicted_words: ' ['<SOS>', 'so', 'remember', 'going', 'to', 'lunge', 'into', 'that', 'forward', 'advanced', 'level', 'lunge', 'with', 'the', 'back', 'leg', 'is', 'straight', 'do', 'a', 'reverse', '<EOS>']\n","Epoch: 390, Cost: 0.05337138389478679\n","'predicted_words: ' ['<SOS>', 'today', 'like', 'the', 'do', 'about', 'it', 'as', 'getting', 'your', 'car', 'painted', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 400, Cost: 0.029860268868678423\n","'predicted_words: ' ['<SOS>', 'so', 'want', 'see', 'the', 'difference', 'in', 'the', 'top', 'and', 'the', 'bottom', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 410, Cost: 0.021991566759189247\n","'predicted_words: ' ['<SOS>', 'the', 'then', 'we', 'were', 'talking', 'primarily', 'about', 'stories', 'whether', 'its', 'short', 'stories', 'or', 'novels', 'but', 'this', 'actually', 'also', 'applies', 'to', '<EOS>']\n","Epoch: 420, Cost: 0.033448167804939054\n","'predicted_words: ' ['<SOS>', 'but', 'lets', 'are', 'a', 'few', 'disadvantages', 'to', 'impromptu', 'speaking', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 430, Cost: 0.03163604506429423\n","'predicted_words: ' ['<SOS>', 'now', 'what', 'ahead', 'and', 'fill', 'in', 'everywhere', 'that', 'you', 'gotta', 'fill', 'in', 'and', 'look', 'at', 'it', 'and', 'well', 'wait', 'for', '<EOS>']\n","Epoch: 440, Cost: 0.02090318461328193\n","'predicted_words: ' ['<SOS>', 'another', 'to', 'have', 'a', 'group', 'of', 'women', 'doing', 'it', 'with', 'you', 'or', 'even', 'friends', 'or', 'a', 'spouse', 'someone', 'thats', 'there', '<EOS>']\n","Epoch: 450, Cost: 0.021917390139100865\n","'predicted_words: ' ['<SOS>', 'elizabeth', 'you', 'temporary', 'breathe', 'is', 'the', 'way', 'were', 'supposed', 'to', 'breathe', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 460, Cost: 0.02804964241632088\n","'predicted_words: ' ['<SOS>', 'so', 'keep', 'two', 'squat', 'develops', 'your', 'teardrop', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 470, Cost: 0.01402034234100332\n","'predicted_words: ' ['<SOS>', 'a', 'flyer', 'is', 'a', 'great', 'way', 'to', 'promote', 'the', 'sponsor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Epoch: 480, Cost: 0.0141720500326267\n","'predicted_words: ' ['<SOS>', 'all', 'example', 'if', 'there', 'is', 'somebody', 'coming', 'at', 'you', 'with', 'road', 'rage', 'it', 'is', 'probably', 'best', 'not', 'to', 'block', 'not', '<EOS>']\n","Epoch: 490, Cost: 0.018689898959430004\n","'predicted_words: ' ['<SOS>', 'just', 'was', 'sacrilegious', 'to', 'dissect', 'the', 'human', 'body', 'so', 'the', 'systems', 'of', 'acupuncture', 'acupressure', 'as', 'well', 'as', 'the', 'use', 'of', '<EOS>']\n","Triaining loss:  129.11381285148025\n","This function took 5351.281431913376 second to complete.\n"]}],"source":["# 訓練開始\n","\n","print(f'詞向量的形狀', embedding_stack_pt.shape)\n","print(f'輸入層大小:', EMBEDDING_DIM)\n","print(f'詞彙表大小:', VOCAB_SIZE)\n","print(f'是否有用到 GPU:', device)\n","print(f'Teacher Forcing Ratio:', TEACHER_FORCING_RATIO)\n","# print(f'詞索引表:', word_index)\n","\n","model = VideoTextModel(embedding_stack_pt, EMBEDDING_DIM, VOCAB_SIZE, TEACHER_FORCING_RATIO).to(device)\n","optimizer = Adam(model.parameters())\n","# loss_function = nn.CrossEntropyLoss()\n","loss_function = nn.NLLLoss()\n","\n","train(model, optimizer, mini_trains, device)"]},{"cell_type":"markdown","metadata":{"id":"LZVSHPj3n7MQ"},"source":["### 6. 驗證 Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXJgq6WioCE9"},"outputs":[],"source":["# 建立驗證方法\n","\n","import torch\n","from torch.utils.data import DataLoader\n","\n","def validate(model, mini_vals, device):\n","    model.eval()\n","    correct = 0\n","    total_loss = 0\n","    total_samples = 0\n","\n","    with torch.no_grad():\n","        for videos, sentences in mini_vals:\n","\n","            # to(device)\n","            videos = videos.float().to(device)\n","            sentences = sentences.long().to(device)\n","            # 產出 outputs\n","            outputs = model(videos, sentences)\n","\n","            # probabilities\n","            # softmax\n","            probabilities = nn.functional.log_softmax(outputs, dim = -1)\n","            # 取得最高的機率\n","            predicted_indices = torch.argmax(probabilities, dim = -1)\n","            # 生成預測字句\n","            predicted_words = [reversed_indices[idx.item()] for idx in predicted_indices[0]]\n","\n","            # Flatten\n","            probabilities_flatten = torch.flatten(probabilities, end_dim=1)\n","            sentence_flatten = torch.flatten(sentences, end_dim=-1)\n","\n","            # 計算 loss\n","            loss = loss_function(probabilities_flatten, sentence_flatten)\n","            total_loss += loss.item()\n","\n","            # 計算正確預測數量\n","            correct += predicted_indices.eq(sentences).sum().item()\n","            total_samples += sentence_flatten.size(0)\n","\n","            # 印出預測字句\n","            print(f\"'predicted_words: ' {predicted_words}\")\n","\n","    avg_loss = total_loss / len(mini_vals)\n","    accuracy = correct / total_samples\n","\n","    print(f'Validation loss: {avg_loss}')\n","    print(f'Validation accuracy: {accuracy * 100:.2f}%')"]},{"cell_type":"markdown","metadata":{"id":"gb2GWhewoz2_"},"source":["#### 6.1 驗證開始"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWeUznBZo3xS","outputId":"bb5faff1-69f6-488a-bc34-f6781dabb748","executionInfo":{"status":"ok","timestamp":1723021317538,"user_tz":-480,"elapsed":4709,"user":{"displayName":"C sc201mar24","userId":"09455476244381582499"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["'predicted_words: ' ['<SOS>', 'you', 'dress', 'for', 'wind', 'chill', 'not', 'for', 'the', 'temperature', 'that', 'you', 'have', 'outside', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'this', 'will', 'get', 'you', 'through', 'a', 'camping', 'trip', 'but', 'youll', 'probably', 'want', 'to', 'replace', 'your', 'pole', 'after', 'that', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'how', 'does', 'a', 'snake', 'grow', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'let', 'me', 'show', 'you', 'with', 'a', 'wall', 'just', 'in', 'case', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'this', 'brings', 'up', 'the', 'visual', 'basic', 'code', 'editor', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'now', 'we', 'got', 'our', 'ice', 'in', 'a', 'glass', 'and', 'were', 'going', 'to', 'do', 'one', 'shot', 'of', 'gin', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'you', 'know', 'pause', 'no', 'surprise', 'there', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'ask', 'them', 'where', 'the', 'teammates', 'of', 'the', 'other', 'team', 'are', 'so', 'you', 'can', 'be', 'able', 'to', 'be', 'able', 'not', 'get', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'go', 'ahead', 'and', 'pour', 'it', 'in', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'we', 'dont', 'have', 'to', 'do', 'anything', 'anymore', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'okay', 'its', 'all', 'the', 'way', 'around', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'it', 'was', 'a', 'little', 'independent', 'movie', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'the', 'cucumber', 'is', 'not', 'stiff', 'anymore', 'i', 'mean', 'it', 'would', 'still', 'break', 'and', 'when', 'you', 'eat', 'it', 'it', 'has', 'a', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'next', 'we', 'will', 'do', 'a', 'tablespoon', 'of', 'apricot', 'brandy', 'and', 'also', 'a', 'tablespoon', 'of', 'triple', 'sec', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'you', 'want', 'it', 'right', 'in', 'front', 'of', 'your', 'solar', 'plexus', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'so', 'were', 'going', 'to', 'go', 'up', 'and', 'down', 'lets', 'switch', 'hands', 'down', 'and', 'up', 'down', 'and', 'up', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'i', 'did', 'monster', 'with', 'charlize', 'theron', 'in', '2004', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'so', 'lets', 'start', 'with', 'the', 'one', 'hand', 'going', 'up', 'and', 'down', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'other', 'things', 'you', 'might', 'run', 'into', 'is', 'a', 'broken', 'pole', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'so', 'breathing', 'leather', 'leash', 'you', 'know', 'your', 'tools', 'are', 'are', 'your', 'biggest', 'asset', 'when', 'youre', 'working', 'with', 'your', 'dog', 'or', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'we', 'want', 'to', 'control', 'the', 'motion', 'and', 'use', 'his', 'energy', 'against', 'him', 'as', 'much', 'as', 'possible', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'it', 'is', 'great', 'if', 'you', 'have', 'one', 'of', 'these', 'really', 'big', 'measuring', 'cups', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'in', 'the', 'next', 'clip', 'well', 'move', 'on', 'to', 'the', 'lower', 'half', 'of', 'his', 'body', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'more', 'on', 'the', 'warm', 'side', 'than', 'not', 'hot', 'or', 'cold', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'we', 'got', 'our', 'martini', 'glass', 'and', 'a', 'strainer', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'if', 'they', 'need', 'to', 'let', 'the', 'hem', 'out', 'because', 'you', 'can', 'still', 'let', 'the', 'pants', 'out', 'and', 'still', 'have', 'some', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'then', 'what', 'i', 'like', 'to', 'do', 'is', 'go', 'on', 'with', 'my', 'fiber', 'pliable', 'paste', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'if', 'you', 'were', 'to', 'have', 'a', 'sidewall', 'like', 'this', 'it', 'might', 'just', 'shave', 'off', 'a', 'nice', 'top', 'layer', 'of', 'it', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'hi', 'everybody', 'im', 'john', 'graden', 'from', 'the', 'martial', 'arts', 'teachers', 'association', 'and', 'johngradencom', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'remember', 'its', 'how', 'to', 'prepare', 'and', 'survive', 'for', 'divorce', 'is', 'never', 'easy', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'remember', 'anything', 'is', 'possible', 'with', 'a', 'little', 'creativity', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'now', 'first', 'of', 'all', 'i', 'want', 'to', 'tell', 'you', 'when', 'you', 'are', 'doing', 'business', 'over', 'the', 'phone', 'you', 'automatically', 'lose', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'im', 'going', 'to', 'show', 'you', 'how', 'to', 'make', 'a', 'razberi', 'sunsplash', 'a', 'wonderfully', 'fruity', 'cocktail', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'your', 'upper', 'body', 'you', 'do', 'not', 'want', 'to', 'be', 'timid', 'or', 'shy', 'i', 'know', 'it', 'is', 'going', 'to', 'feel', 'a', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'if', 'one', 'is', 'drinking', 'water', 'were', 'going', 'to', 'get', 'into', 'these', 'in', 'a', 'little', 'more', 'detail', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'my', 'name', 'is', 'zephyr', 'clarke-dolberg', 'from', 'miami', 'dog', 'training', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'we', 'just', 'need', 'a', 'little', 'bit', 'of', 'water', 'in', 'here', 'at', 'the', 'bottom', 'just', 'a', 'little', 'bit', 'of', 'water', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'now', 'depending', 'on', 'the', 'size', 'of', 'the', 'sponsorship', 'you', 'can', 'offer', 'quarter', 'page', 'half', 'page', 'or', 'full-page', 'ads', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'a', 'common', 'problem', 'with', 'fish', 'is', 'ick', 'which', 'is', 'tiny', 'white', 'spots', 'over', 'the', 'entire', 'fish', 'itself', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'but', 'when', 'you', 'think', 'about', 'that', 'is', 'that', 'going', 'to', 'get', 'the', 'job', 'done', 'for', 'you', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'draw', 'the', 'top', 'edges', 'of', 'it', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'so', 'there', 'we', 'go', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'and', 'youre', 'going', 'to', 'garnish', 'this', 'with', 'a', 'cherry', 'and', 'a', 'lemon', 'twist', 'that', 'you', 'can', 'twist', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'all', 'of', 'those', 'things', 'can', 'affect', 'how', 'your', 'character', 'acts', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'i', 'am', 'going', 'to', 'let', 'this', 'go', 'until', 'i', 'dont', 'see', 'any', 'bubbles', 'in', 'there', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'its', 'great', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'the', 'is', 'one', 'of', 'my', 'favorite', 'things', 'to', 'use', 'for', 'hair', 'skin', 'lips', 'soars', 'everything', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'elizabeth', 'cutting', 'these', 'down', 'im', 'going', 'to', 'cut', 'all', 'the', 'way', 'through', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'you', 'have', 'to', 'clean', 'this', 'off', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'as', 'he', 'attacks', 'just', 'turn', 'and', 'go', 'right', 'in', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'you', 'got', 'the', 'top', 'of', 'his', 'robe', 'his', 'sleeves', 'little', 'belt', 'there', 'his', 'hands', 'and', 'that', 'will', 'work', 'well', 'for', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'others', 'can', 'just', 'not', 'connect', 'with', 'that', 'energy', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'pour', 'that', 'into', 'your', 'glass', 'and', 'then', 'were', 'going', 'to', 'add', 'to', 'that', 'three', 'fourths', 'of', 'an', 'ounce', 'of', 'coconut', '<EOS>']\n","'predicted_words: ' ['<SOS>', 'so', 'i', 'have', 'to', 'trim', 'this', 'as', 'well', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n","Validation loss: 0.021525343485134525\n","Validation accuracy: 99.53%\n"]}],"source":["validate(model, mini_vals, device)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}