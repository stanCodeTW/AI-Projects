{"cells":[{"cell_type":"markdown","metadata":{"id":"m1arIofd987S"},"source":["# Setup for GNN Training"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7318,"status":"ok","timestamp":1722178880373,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"8SFk1fmtF_ay","outputId":"a7644102-fc52-4087-845d-273b30ee3796"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# mount to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":566,"status":"ok","timestamp":1722178883707,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"AziBw9gbIzD1","outputId":"7e3d2ff2-00d8-44a3-e3ad-03e56068134f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/network_processing\n"]}],"source":["# move to the working folder\n","FOLDERNAME = 'network_processing'\n","%cd drive/MyDrive/$FOLDERNAME/"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1245,"status":"ok","timestamp":1722178888634,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"6iJBlTWXc24q"},"outputs":[],"source":["# # install torch_geometric if necessary\n","# !pip install torch_geometric"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4226,"status":"ok","timestamp":1722178895178,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"4ql12iSJGl1H"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from tqdm import tqdm\n","import re\n","import random\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n","from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor\n","\n","import networkx as nx\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":472,"status":"ok","timestamp":1722178898007,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"tO6JzkVsHJOU","outputId":"c98eb3c2-6a15-44d7-bfcf-cce9d2cf774e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device cpu\n"]}],"source":["if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","print('Device', device)"]},{"cell_type":"markdown","metadata":{"id":"p7WeWyco_TV8"},"source":["# Build GNN Model"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":444,"status":"ok","timestamp":1722178902078,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"C827VDreQILs"},"outputs":[],"source":["# build the GAT model\n","class GAT(nn.Module):\n","    def __init__(self, input_dim, gat_hidden_dim, output_dim, num_gat_layers, num_heads):\n","        super(GAT, self).__init__()\n","        self.gat_layers = nn.ModuleList([\n","            GATConv(input_dim if i == 0 else gat_hidden_dim * num_heads, gat_hidden_dim, heads=num_heads, dropout=0.2)\n","            for i in range(num_gat_layers)\n","        ])\n","        self.predict = nn.Linear(gat_hidden_dim * num_heads, output_dim)\n","        self.edge_weight = None\n","        self.edge = None\n","\n","    def forward(self, x, edge_index):\n","        self.edge = edge_index\n","        for gat in self.gat_layers:\n","            x, weight = gat(x, edge_index, return_attention_weights=True)\n","            self.edge_weight = weight[1]\n","            self.edge = weight[0]\n","            x = F.relu(x)\n","        x = self.predict(x)\n","        return x\n","\n","    def get_edge_weight(self):\n","        return self.edge_weight\n","\n","    def get_edge(self):\n","        return self.edge"]},{"cell_type":"markdown","metadata":{"id":"MgNcDCzzBIBi"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1722178906094,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"PJ9psAHABXnZ"},"outputs":[],"source":["# load the company relationship data\n","file_path = './Company_Relationship.xlsx'\n","data = pd.read_excel(file_path, sheet_name='Total_Network', header=None)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1722178907316,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"-hp0HUWlB05S"},"outputs":[],"source":["# process the company relationship data\n","edges = []\n","for i in range(data.shape[0]):\n","    for row_index, j in enumerate(data.iloc[i, 3:].dropna().to_list()):\n","        numbers = re.findall(r'-?\\d+', j)\n","        if len(numbers) < 2:\n","            continue\n","        start, end = int(numbers[0]), int(numbers[1])\n","        edges.append((start, end))\n","\n","edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":465,"status":"ok","timestamp":1722178910670,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"0H84qq86Bdta"},"outputs":[],"source":["# load the output data from imaging processing and extract features\n","output_path = './ResNet_output_vectors_training.csv'\n","df_image = pd.read_csv(output_path)\n","\n","stocks = df_image['stock']\n","dates = df_image['date']\n","vectors = df_image['vector'].apply(lambda x: np.fromstring(x.strip('[]'), sep=',')).tolist()"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3969,"status":"ok","timestamp":1722178964301,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"nH1ugAVWdPpF"},"outputs":[],"source":["# Load the macroeconomic data\n","macro_path = './normalized_macro.csv'\n","df_macro = pd.read_csv(macro_path)\n","\n","# Ensure the date formats are consistent\n","df_macro['Date'] = pd.to_datetime(df_macro['Date'])\n","df_image['date'] = pd.to_datetime(df_image['date'])\n","\n","# Merge the ResNet data and macroeconomic data on date\n","merged_df = pd.merge(df_image, df_macro, left_on='date', right_on='Date', how='inner')\n","\n","# Drop the 'Date' column from macro data as it's redundant after merging\n","merged_df = merged_df.drop(columns=['Date'])\n","\n","# Extract combined vectors without titles\n","vectors_combined = []\n","for idx, row in merged_df.iterrows():\n","    resnet_vector = np.fromstring(row['vector'].strip('[]'), sep=',')\n","    macro_vector = row[['USD/TWD', 'VIX', ' Crude Oil', 'Gold', 'CPI', 'Unemployment Rate', 'Interest Rate', 'M2']].values.astype(float)\n","    combined_vector = np.concatenate([resnet_vector, macro_vector])\n","    vectors_combined.append(combined_vector)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":806,"status":"ok","timestamp":1722178968171,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"_Yoks-Ak3WTm","outputId":"6bc1979e-de8b-4961-8b94-692498f14fb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-11-64e583444bc1>:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n","  node_features = torch.tensor(vectors_combined, dtype=torch.float)\n"]}],"source":["# Create a DataFrame for the combined data\n","combined_df = pd.DataFrame({\n","    'stock': merged_df['stock'],\n","    'date': merged_df['date'],\n","    'vector': vectors_combined\n","})\n","\n","# Convert vectors to the required string format\n","combined_df['vector'] = combined_df['vector'].apply(lambda x: ','.join(map(str, x)))\n","\n","# Prepare the graph data\n","node_features = torch.tensor(vectors_combined, dtype=torch.float)\n","data = Data(x=node_features, edge_index=edge_index)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":829,"status":"ok","timestamp":1722178971590,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"Fxn9ZQsRd5wn","outputId":"32916d85-2be4-4132-8aad-7da0d8fd4214"},"outputs":[{"name":"stdout","output_type":"stream","text":["      stock       date                                             vector\n","0      2912 2017-02-10  -0.4871345,1.0913699,-1.3290397,0.2241055,0.25...\n","1      3008 2017-02-10  -0.29821175,0.1569825,-0.2565347,0.25301692,0....\n","2      3045 2017-02-10  -0.40963504,2.0191028,-2.5389774,1.0132645,0.6...\n","3      3481 2017-02-10  -0.35229602,0.007964615,-0.03224269,-0.0162423...\n","4      3711 2017-02-10  -0.3067895,0.4327159,-0.3387887,0.09546754,0.1...\n","...     ...        ...                                                ...\n","7504   1101 2017-01-17  -0.42047712,0.9486824,-1.0586202,0.5972066,0.5...\n","7505   1102 2017-01-17  -0.6562908,2.2380335,-2.0883741,1.2907951,0.72...\n","7506   1216 2017-01-17  -0.44098958,0.27151826,-0.04504534,-0.24088496...\n","7507   1301 2017-01-17  -0.4780133,1.2899575,-1.0223458,0.851885,0.473...\n","7508   1303 2017-01-17  -0.13169901,0.48342395,-0.64879555,0.4947278,0...\n","\n","[7509 rows x 3 columns]\n"]}],"source":["print(combined_df)"]},{"cell_type":"markdown","metadata":{"id":"XyG-PXptBjKy"},"source":["# Training"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":844,"status":"ok","timestamp":1722178986639,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"PoQgq-dWCJyx"},"outputs":[],"source":["# initialize the GAT model\n","input_dim = node_features.size(1)\n","gat_hidden_dim = 10\n","output_dim = 1\n","num_gat_layers = 2\n","num_heads = 2\n","model = GAT(input_dim, gat_hidden_dim, output_dim, num_gat_layers, num_heads)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":856,"status":"ok","timestamp":1722178989612,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"0tZ0fBq3Uuux"},"outputs":[],"source":["# moce data and model to device\n","data = data.to(device)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1722178991402,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"_852_OXlCe1Z"},"outputs":[],"source":["# constants for model training\n","NUM_EPOCHS = 100\n","PRINT_EVERY = 10"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1722178993763,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"UKOLpgQ6CSE7"},"outputs":[],"source":["# define loss and optimizer\n","loss_function = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1722178996785,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"um_cN1gOCWg_"},"outputs":[],"source":["# label for testing accuracy\n","label = torch.randint(0, 2, (node_features.size(0),), dtype=torch.float).unsqueeze(1)  # dummy labels for test"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2197,"status":"ok","timestamp":1722179000187,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"_DUTTGYlC3Zl","outputId":"46bcc5cd-904e-4d68-9ebf-5edba8c9fa31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 10/100, Loss: 0.6932531595230103, Training Accuracy: 50.01%\n","Epoch 20/100, Loss: 0.6924663186073303, Training Accuracy: 51.21%\n","Epoch 30/100, Loss: 0.691675066947937, Training Accuracy: 52.18%\n","Epoch 40/100, Loss: 0.6917874217033386, Training Accuracy: 51.54%\n","Epoch 50/100, Loss: 0.6904712319374084, Training Accuracy: 52.90%\n","Epoch 60/100, Loss: 0.6900879144668579, Training Accuracy: 53.23%\n","Epoch 70/100, Loss: 0.689365804195404, Training Accuracy: 52.72%\n","Epoch 80/100, Loss: 0.6897796988487244, Training Accuracy: 53.55%\n","Epoch 90/100, Loss: 0.6877066493034363, Training Accuracy: 53.56%\n","Epoch 100/100, Loss: 0.6856527924537659, Training Accuracy: 53.91%\n","Training completed.\n"]}],"source":["# training loop\n","model.train()\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    optimizer.zero_grad()\n","    out = model(data.x, data.edge_index)\n","    loss = loss_function(out, label)\n","    loss.backward()\n","    optimizer.step()\n","\n","    with torch.no_grad():\n","        predictions = torch.sigmoid(out)\n","        predicted_labels = (predictions > 0.5).float()\n","        correct = (predicted_labels == label).sum().item()\n","        total = label.size(0)\n","        accuracy = correct / total\n","\n","    if (epoch + 1) % PRINT_EVERY == 0:\n","        print(f'Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {loss.item()}, Training Accuracy: {accuracy * 100:.2f}%')\n","\n","print('Training completed.')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1722179006420,"user":{"displayName":"AIApplication stanCode","userId":"09512301440120967980"},"user_tz":-480},"id":"fW7E600TRcGY","outputId":"d03fb803-0828-4e4d-e7a4-91ed6140c990"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results saved to 'training_results.csv'\n"]}],"source":["# Inference to obtain final vectors\n","model.eval()\n","with torch.no_grad():\n","    final_vectors = model(data.x, data.edge_index)\n","\n","# Convert predictions to a single vector per stock\n","final_vectors = final_vectors.squeeze().cpu().numpy()\n","\n","# Adjust the length of stocks and dates to match final_vectors\n","original_length = len(final_vectors)\n","\n","# Filter stocks and dates to match the number of final_vectors\n","stocks_filtered = stocks[:original_length]\n","dates_filtered = dates[:original_length]\n","\n","# prepare the output data for CSV\n","output_data = {\n","    \"stock\": stocks_filtered,\n","    \"date\": dates_filtered,\n","    \"vector\": final_vectors\n","}\n","\n","output_df = pd.DataFrame(output_data)\n","output_df.to_csv('training_results.csv', index=True)\n","print(\"Results saved to 'training_results.csv'\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOEjQ6MaNxT3lM5YcTs/LRG","collapsed_sections":["sMfMZsB1AHf2"],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
