{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP0YfhOJh8B6BwpMEz4VsbO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2fBPFIvCN_e","executionInfo":{"status":"ok","timestamp":1727097907098,"user_tz":-480,"elapsed":26352,"user":{"displayName":"A Group","userId":"16248367019244849851"}},"outputId":"e92e5d9a-3ad2-48e0-af5f-d1abb1e54e30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/Group_A_Project\n"]}],"source":["# Mount to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Define Project Folder\n","FOLDERNAME = 'Colab Notebooks/Group_A_Project'\n","%cd drive/MyDrive/$FOLDERNAME\n","\n"]},{"cell_type":"code","source":["# Import libraries\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","import numpy as np\n","import math"],"metadata":{"id":"jpvN64NAESxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FoREc5dOCVNn","executionInfo":{"status":"ok","timestamp":1727097909810,"user_tz":-480,"elapsed":509,"user":{"displayName":"A Group","userId":"16248367019244849851"}},"outputId":"0b50da8b-63e2-4228-9b2a-eaf5b28b287c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"],"metadata":{"id":"A6OAYOz_CW39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_data = pd.read_csv('Amazon_Unlocked_Mobile.csv')"],"metadata":{"id":"5YvzmTy5CYO7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reviews = raw_data['Reviews'].astype(str)\n","labels = raw_data['Rating']\n","labels.replace({1: 0, 2: 0, 3: 1, 4: 2, 5: 2}, inplace=True)"],"metadata":{"id":"qxR5UfSkCZ65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patterns = ['<br />', '--', '.', ',', '!', '?', ')', '(', ';', ':', '*', '~', '_', \"'\", '\"']\n","replacements = [' '] * len(patterns)"],"metadata":{"id":"fp8ytqA8Ccto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocessing(reviews, patterns, replacements):\n","    cleaned_reviews = []\n","    for i in range(len(reviews)):\n","        review = reviews[i].lower()\n","        for pattern, replacement in zip(patterns, replacements):\n","            review = review.replace(pattern, replacement)\n","        cleaned_reviews.append(review)\n","    return cleaned_reviews"],"metadata":{"id":"GWFoIB5tCeGP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cleaned_reviews = preprocessing(reviews, patterns, replacements)"],"metadata":{"id":"d2eXEf-xCjdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(cleaned_reviews)\n","sequences = tokenizer.texts_to_sequences(cleaned_reviews)\n"],"metadata":{"id":"121RJUemCk8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.sequence import pad_sequences\n","sequence_len = 5000\n","padded_sequences = pad_sequences(sequences, maxlen=sequence_len, padding='post')"],"metadata":{"id":"I-r2mMUjCmIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare labels\n","labels = labels.values"],"metadata":{"id":"GgV23y2CCobQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train/Val split\n","train_size = 100000\n","val_size = 10000"],"metadata":{"id":"WpaCc6MICqY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = padded_sequences[:train_size]\n","train_labels = labels[:train_size]\n","val_data = padded_sequences[train_size:train_size + val_size]\n","val_labels = labels[train_size:train_size + val_size]"],"metadata":{"id":"Fzmcz7HZCr3U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert to tensors\n","train_data_tensor = torch.tensor(train_data, dtype=torch.long)\n","train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n","val_data_tensor = torch.tensor(val_data, dtype=torch.long)\n","val_labels_tensor = torch.tensor(val_labels, dtype=torch.long)\n"],"metadata":{"id":"3RMVThqqCtY2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataloaders\n","batch_size = 32\n","train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n","val_dataset = TensorDataset(val_data_tensor, val_labels_tensor)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"632neOQ6Cu39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Positional Encoding for Transformer\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, embedding_dim, dropout=0.1, max_len=6000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, embedding_dim)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-torch.log(torch.tensor(10000.0)) / embedding_dim))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, :x.size(1), :]\n","        return self.dropout(x)\n","\n","# Define Transformer Model\n","class TransformerModel(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_heads, num_layers, dropout):\n","        super(TransformerModel, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.pos_encoder = PositionalEncoding(embedding_dim, dropout)\n","        encoder_layer = nn.TransformerEncoderLayer(embedding_dim, num_heads, hidden_dim, dropout)\n","        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n","        self.fc = nn.Linear(embedding_dim, output_dim)\n","\n","    def forward(self, x):\n","        x = self.embedding(x) * math.sqrt(self.embedding.embedding_dim)\n","        x = self.pos_encoder(x)\n","        x = self.transformer(x)\n","        x = self.fc(x.mean(dim=1))  # global average pooling\n","        return x\n","\n","\n"],"metadata":{"id":"42kp1Be_CwRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model parameters\n","embedding_dim = 128\n","hidden_dim = 256\n","output_dim = 3\n","num_heads = 8\n","num_layers = 2\n","dropout = 0.5\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","model = TransformerModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_heads, num_layers, dropout)\n","model = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9wkIheIEC4UV","executionInfo":{"status":"ok","timestamp":1727098035695,"user_tz":-480,"elapsed":818,"user":{"displayName":"A Group","userId":"16248367019244849851"}},"outputId":"aa7e2da9-578a-48ef-8312-49b4e5a7b284"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}]},{"cell_type":"code","source":["# Loss and optimizer\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training function\n","def train(model, train_loader, val_loader, device, loss_function, optimizer, num_epochs):\n","    model.train()\n","    for epoch in range(num_epochs):\n","        total_loss = 0\n","        correct = 0\n","        for data, target in train_loader:\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = loss_function(output, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            correct += (output.argmax(1) == target).sum().item()\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader)}, Accuracy: {correct/len(train_loader.dataset)}')\n","\n","        evaluate(model, val_loader, device)\n","\n","# Evaluation function\n","def evaluate(model, val_loader, device):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            correct += (output.argmax(1) == target).sum().item()\n","    print(f'Validation Accuracy: {correct/len(val_loader.dataset)}')\n","\n","\n"],"metadata":{"id":"-ISXCNvJC6d3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 10\n","train(model, train_loader, val_loader, device, loss_function, optimizer, num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bSOxuII_DBax","outputId":"b68fccf2-8ee2-4aad-e686-12f21531aeea"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch [1/10], Loss: 0.7507190199565887, Accuracy: 0.70581\n","Validation Accuracy: 0.6585\n","Epoch [2/10], Loss: 0.7443839913463592, Accuracy: 0.70574\n","Validation Accuracy: 0.6583\n","Epoch [3/10], Loss: 0.7381377372360229, Accuracy: 0.70571\n","Validation Accuracy: 0.6581\n","Epoch [4/10], Loss: 0.7288530111789704, Accuracy: 0.70555\n","Validation Accuracy: 0.6587\n","Epoch [5/10], Loss: 0.7157057019138336, Accuracy: 0.70726\n","Validation Accuracy: 0.6601\n","Epoch [6/10], Loss: 0.7023661456298829, Accuracy: 0.71259\n","Validation Accuracy: 0.6638\n"]}]}]}