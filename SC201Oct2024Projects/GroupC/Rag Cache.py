import requests
import openrouteservice
import time
from geopy.distance import geodesic
from tqdm import tqdm
import json
import os
import pandas as pd
from collections import defaultdict
from datetime import datetime
import openai
from openai import OpenAI
import gradio as gr
import chromadb
from chromadb import PersistentClient
from pathlib import Path

# --------------------- API é‡‘é‘°è¨­å®š ---------------------#
os.environ[
    "OPENAI_API_KEY"] = 'YOUR_OPENAI_API_KEY'  # æ›¿æ›ç‚ºä½ çš„ API Key
openai.api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

API = 'AIzaSyAbeUNGBay9f8K1k46hNIbKIvumHZVjGgc'  # Google Maps API Key
OR_API_KEY = "5b3ce3597851110001cf6248935e4404f78c443fbec30b30ca472277"  # OpenRouteService API Key

# --------------------- åœ°å€ Alias èˆ‡å¿«å–è¨­å®š ---------------------#
# åœ°å€ alias å°æ‡‰ï¼Œè®“ä½ å¯ä»¥ä»¥ç°¡ç¨±è¼¸å…¥ï¼Œä¸¦è½‰æ›æˆå®Œæ•´åœ°å€
ADDRESS_ALIAS = {
    "ä½å®¶": "å°åŒ—å¸‚ä¿¡ç¾©å€æ¾å±±è·¯123è™Ÿ"
}


# è‹¥è¼¸å…¥çš„åœ°å€åœ¨ alias ä¸­ï¼Œå‰‡ä»¥ alias æ‰€å°æ‡‰çš„å¯¦éš›åœ°å€ä½œç‚ºæœå°‹ä¾æ“š
def get_real_address(address):
    return ADDRESS_ALIAS.get(address.strip(), address.strip())


# å¿«å–è³‡æ–™å­˜æ”¾è³‡æ–™å¤¾ï¼ˆæœƒè‡ªå‹•å»ºç«‹ï¼‰
CACHE_FOLDER = Path("./restaurant_cache")
CACHE_FOLDER.mkdir(exist_ok=True)


def get_cache_filename(address):
    safe_name = address.replace(" ", "_")
    return CACHE_FOLDER / f"restaurant_cache_{safe_name}.json"


def load_restaurants_cache(address):
    cache_file = get_cache_filename(address)
    if cache_file.exists():
        with open(cache_file, "r", encoding="utf-8") as f:
            return json.load(f)
    return None


def save_restaurants_cache(address, restaurants):
    cache_file = get_cache_filename(address)
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(restaurants, f, ensure_ascii=False, indent=2)


# --------------------- Embedding + Parquet å¿«å– ---------------------#
csv_path = './labeled_history_dataset.csv'
parquet_path = './label_vectors_with_weight.parquet'


def calculate_weight(row, half_life_months=3):
    now = datetime.now()
    count_score = min(row['count'] / 10, 1.0)
    recency_months = (now - pd.to_datetime(row['latest_date'])).days / 30
    recency_score = 0.5 ** (recency_months / half_life_months)
    return round((count_score + recency_score) / 2, 4)


def get_label_embedding(label):
    response = client.embeddings.create(
        input=label,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding


if os.path.exists(parquet_path):
    print("ğŸŸ¢ å·²æ‰¾åˆ° parquet æª”æ¡ˆï¼Œç›´æ¥è¼‰å…¥å·²è¨ˆç®—å¥½çš„ embeddingï¼")
    label_stats = pd.read_parquet(parquet_path)
else:
    print("ğŸ”„ æ‰¾ä¸åˆ° parquetï¼Œå¾ CSV å»ºç«‹ embedding...")
    df = pd.read_csv(csv_path)
    df_exploded = df.assign(label=df['labels'].str.split(',')).explode('label')
    df_exploded['label'] = df_exploded['label'].str.strip()
    label_stats = df_exploded.groupby('label').agg(
        count=('label', 'count'),
        latest_date=('Date', 'max')
    ).reset_index()
    label_stats['weight'] = label_stats.apply(calculate_weight, axis=1)
    embeddings = []
    for label in tqdm(label_stats['label'].tolist(), desc="Embedding"):
        embeddings.append(get_label_embedding(label))
    label_stats['embedding'] = embeddings
    label_stats.to_parquet(parquet_path, index=False)
    print("âœ… å·²å„²å­˜ embedding è‡³ parquetï¼")

# --------------------- å»ºç«‹æˆ–é‡å»º Chroma è³‡æ–™åº« ---------------------#
chroma_path = './chroma_db'
chroma_client = PersistentClient(path=chroma_path)
collection = chroma_client.get_or_create_collection("label_vectors_with_count_and_date")

if collection.count() > 0:
    all_data = collection.get()
    collection.delete(ids=all_data['ids'])
    print("ğŸ§¹ å·²æ¸…ç©ºåŸæœ‰è³‡æ–™")

for i, row in tqdm(label_stats.iterrows(), total=len(label_stats)):
    collection.add(
        ids=[f"label_{i}"],
        documents=[row['label']],
        embeddings=[row['embedding']],
        metadatas=[{
            'label': row['label'],
            'count': row['count'],
            'latest_date': str(row['latest_date']),
            'weight': row['weight']
        }]
    )
print(f"âœ… Chroma collection å®Œæˆï¼Œå…± {collection.count()} ç­†è³‡æ–™")


# --------------------- è¼”åŠ©å‡½å¼ ---------------------#
def together(num, minutes):
    if num == 1:
        return 'walking', 'foot-walking', minutes
    return 'driving', 'driving-car', minutes


def transform(address):
    url = f"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={API}"
    data = requests.get(url).json()
    if data.get('status') == 'OK':
        loc = data['results'][0]['geometry']['location']
        return loc['lat'], loc['lng']
    return None, None


def get_isochrone(lat, lng, profile, range_time):
    client_or = openrouteservice.Client(key=OR_API_KEY)
    location = [lng, lat]
    iso = client_or.isochrones(locations=[location], profile=profile, range=[range_time])

    def get_max_distances(origin, iso):
        dists = []
        for f in iso['features']:
            max_d = max(
                geodesic((origin[1], origin[0]), (pt[1], pt[0])).m
                for poly in f['geometry']['coordinates'] for pt in poly
            )
            dists.append(max_d)
        return dists

    return iso, get_max_distances(location, iso)


def search_nearby(lat, lng, radius):
    url = f"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lng}&radius={radius}&type=restaurant&key={API}"
    restaurants = []
    while url:
        res = requests.get(url).json()
        if res.get('status') == 'OK':
            for r in res['results']:
                restaurants.append({
                    'name': r.get('name'),
                    'address': r.get('vicinity'),
                    'place_id': r.get('place_id'),
                    'rating': r.get('rating', 0),
                    'types': r.get('types'),
                    'price_level': r.get('price_level', 'æœªçŸ¥')
                })
            token = res.get("next_page_token")
            url = f"https://maps.googleapis.com/maps/api/place/nearbysearch/json?pagetoken={token}&key={API}" if token else None
            if token: time.sleep(2)
        else:
            break
    return restaurants


def find_restaurant(lat, lng, minutes, mode, radius):
    radius = radius[0]
    restaurants = search_nearby(lat, lng, radius)
    while len(restaurants) < 50 and radius < 20000:
        radius = int(radius * 1.2)
        restaurants = search_nearby(lat, lng, radius)
    return sorted(restaurants, key=lambda x: x['rating'], reverse=True)


def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding


def openai_api(system_msg, user_msg):
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_msg}],
        temperature=0.7
    )
    return res.choices[0].message.content


def combine_input_to_sentence(address, mode, minutes, user_prompt):
    mode_dict = {1: "æ­¥è¡Œ", 2: "é–‹è»Š", 3: "å¤–é€"}
    return f"æˆ‘åœ¨ {address}ï¼Œå¸Œæœ›åœ¨ {minutes} åˆ†é˜ä»¥å…§ï¼Œé€é {mode_dict.get(mode, 'è¡Œå‹•')} å¯ä»¥æ‰¾åˆ°çš„æ¨è–¦ã€‚ä½¿ç”¨è€…é¡å¤–éœ€æ±‚ï¼š{user_prompt}"


# --------------------- Gradio ä¸»ç¨‹å¼ ---------------------#
def gradio_app(address, mode, minutes, user_request, force_refresh=False):
    """
    ä½¿ç”¨è€…è¼¸å…¥åœ°å€ï¼Œç²å–æœ€æ–°çš„é¤å»³è³‡è¨Šï¼Œä¸¦çµåˆéå»çš„ç”¨é¤è¨˜éŒ„èˆ‡æ¬Šé‡åŠ æ¬Šå¾Œçš„ RAG ä¾†æ¨è–¦ã€‚
    è‹¥åœ°å€å±¬æ–¼å›ºå®šåœ°å€ï¼ˆä¾‹å¦‚ã€Œä½å®¶ã€ï¼‰ï¼Œå‰‡å„ªå…ˆè®€å–å¿«å–æª”ï¼Œå¦å‰‡å³æ™‚æœå°‹ã€‚
    """
    try:
        mode_int = int(mode)
        minutes = int(minutes)
    except:
        return "âŒ è«‹ç¢ºèªæ¨¡å¼èˆ‡åˆ†é˜æ•¸æ ¼å¼æ­£ç¢ºã€‚"

    # å–å¾—å¯¦éš›åœ°å€ï¼ˆè‹¥æœ‰ alias å‰‡è½‰æ›ï¼‰
    real_address = get_real_address(address)

    mode_val, profile, minutes_val = together(mode_int, minutes)
    text = combine_input_to_sentence(real_address, mode_int, minutes, user_request)
    text_embedding = get_embedding(text)

    # æŸ¥è©¢å‘é‡è³‡æ–™åº«ï¼Œå–å¾— metadatasï¼ˆå« weightï¼‰
    results = collection.query(
        query_embeddings=[text_embedding],
        n_results=50,
        include=['documents', 'distances', 'metadatas']
    )
    ranked_results = []
    for doc, dist, meta in zip(results["documents"][0], results["distances"][0], results["metadatas"][0]):
        weight = meta.get('weight')
        score = (1 - dist) * weight
        ranked_results.append((doc, score))
    ranked_results.sort(key=lambda x: x[1], reverse=True)
    top_context = "\n".join([doc for doc, _ in ranked_results[:15]])

    # åœ°å€è½‰ç¶“ç·¯åº¦
    lat, lng = transform(real_address)
    if lat is None or lng is None:
        return "ç„¡æ³•å–å¾—è©²åœ°å€çš„ç¶“ç·¯åº¦ï¼Œè«‹ç¢ºèªåœ°å€æ˜¯å¦æ­£ç¢ºã€‚"

    # å–å¾—ç­‰æ™‚ç·šè³‡è¨Š
    _, max_dists = get_isochrone(lat, lng, profile, minutes_val * 60)

    # è‹¥ç‚ºå›ºå®šåœ°å€ï¼ˆä¾‹å¦‚ã€Œä½å®¶ã€ï¼‰ä¸”æœªå¼·åˆ¶åˆ·æ–°ï¼Œå‰‡å„ªå…ˆè®€å–å¿«å–
    fixed_address = "ä½å®¶"  # é€™è£¡å¯ä»¥ä¿®æ”¹æˆä½ çš„å›ºå®šåœ°å€æˆ– alias
    if real_address == ADDRESS_ALIAS.get("ä½å®¶", "ä½å®¶") and not force_refresh:
        cached_restaurants = load_restaurants_cache("ä½å®¶")
        if cached_restaurants is not None:
            restaurants = cached_restaurants
            print("âœ… ä½¿ç”¨å¿«å–çš„é¤å»³çµæœ")
        else:
            print("ğŸš€ å¿«å–ä¸å­˜åœ¨ï¼ŒåŸ·è¡Œå³æ™‚æœå°‹...")
            restaurants = find_restaurant(lat, lng, minutes_val, mode_val, max_dists)
            save_restaurants_cache("ä½å®¶", restaurants)
    else:
        print("ğŸ” å³æ™‚æœå°‹é¤å»³ä¸­...")
        restaurants = find_restaurant(lat, lng, minutes_val, mode_val, max_dists)

    print(f"æ‰¾åˆ° {len(restaurants)} é–“é¤å»³")
    system_message = f"""
    ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„é¤å»³æ¨è–¦ AI åŠ©ç†ï¼Œä½ çš„ç›®æ¨™æ˜¯æ ¹æ“šä½¿ç”¨è€…ç›®å‰ä½ç½®ã€éå¾€æ¶ˆè²»åå¥½ã€RAG æª¢ç´¢çµæœä»¥åŠä½¿ç”¨è€…ç•¶å‰éœ€æ±‚ï¼Œæ¨è–¦æœ€é©åˆçš„é¤å»³ã€‚

    # ğŸ’¡ **è¦å‰‡**
    1. ä»¥ä¸‹æ˜¯æœ€æ–°çš„é¤å»³æ¸…å–®ï¼ˆrestaurantsï¼‰ï¼Œåªèƒ½å¾é€™ä»½æ¸…å–®ä¸­æ¨è–¦ã€‚

    2. ç•¶ä½¿ç”¨è€…æœ‰ç‰¹å®šå“é …éœ€æ±‚ï¼ˆ{user_request}ï¼‰ï¼Œè«‹**å„ªå…ˆæ¨è–¦**ï¼š
       - é¤å»³èœå–®æˆ–æè¿°ä¸­åŒ…å«æ­¤å“é …æˆ–å…¶åŒç¾©è©çš„é¤å»³ã€‚
       - è‹¥æ²’æœ‰å®Œå…¨åŒ¹é…ï¼Œè«‹æ¨è–¦ã€Œé«˜åº¦ç›¸è¿‘é¡åˆ¥ã€çš„é¤å»³ï¼Œä¸¦åœ¨æ¨è–¦ç†ç”±ä¸­è§£é‡‹ç›¸ä¼¼æ€§ã€‚

    3. åŒæ™‚åƒè€ƒä¸‹æ–¹ RAG æª¢ç´¢çµæœï¼ˆéå¾€ç´€éŒ„æ¨™ç±¤ï¼‰é€²è¡Œè¼”åŠ©èªªæ˜ï¼š
       - å¦‚æœæ¨è–¦é¤å»³çš„èœè‰²ã€é¢¨æ ¼æˆ–é¡åˆ¥èˆ‡ RAG æ¨™ç±¤é«˜åº¦åŒ¹é…ï¼Œè«‹åˆ—å‡ºï¼š
         - ç›¸ç¬¦æ¨™ç±¤
         - æ¨™ç±¤åœ¨æ­·å²ç´€éŒ„ä¸­çš„å‡ºç¾é »ç‡æè¿°ï¼ˆã€Œç¶“å¸¸å‡ºç¾ã€ã€ã€Œè¿‘æœŸå¤šæ¬¡å‡ºç¾ã€ç­‰ï¼‰
         - ç‚ºä»€éº¼æ­¤æ¨™ç±¤è®“é€™é–“é¤å»³å€¼å¾—æ¨è–¦
       - å¦‚æœåªæ˜¯ã€Œç›¸ä¼¼ã€è€Œéå®Œå…¨åŒ¹é…ï¼Œä¹Ÿè«‹æ¨™è¨»ã€Œåƒè€ƒäº†ç›¸ä¼¼æ¨™ç±¤ã€ä¸¦è§£é‡‹

    4. è«‹å°æ¯ä¸€é–“æ¨è–¦é¤å»³ï¼Œè¼¸å‡ºä»¥ä¸‹è³‡è¨Šï¼š
       - é¤å»³åç¨±
       - æ¨è–¦åŸå› ï¼ˆèªªæ˜èˆ‡ä½¿ç”¨è€…éœ€æ±‚ã€æ¨™ç±¤çš„é—œè¯æˆ–ç›¸ä¼¼æ€§ï¼Œè‡³å°‘ 2-3 å¥è©±ï¼‰
       - é ä¼°åƒ¹æ ¼ç¯„åœï¼ˆè‹¥æ¸…å–®ä¸­æœ‰æä¾›ï¼‰
       - éå¾€ç´€éŒ„åƒè€ƒï¼ˆåˆ—å‡ºæ¨™ç±¤èˆ‡é »ç‡æè¿°ï¼Œè‹¥ç„¡ç›´æ¥åŒ¹é…å‰‡å¯«ã€Œåƒè€ƒç›¸ä¼¼æ¨™ç±¤ã€ï¼‰

    5. è‹¥æ²’æœ‰æ‰¾åˆ°èˆ‡éœ€æ±‚å®Œå…¨åŒ¹é…çš„é¤å»³ï¼Œè«‹ä½¿ç”¨ã€Œç›¸è¿‘é¤å»³æ¨è–¦ã€ï¼Œä¸¦æ¸…æ¥šæ¨™ç¤ºã€Œç›¸è¿‘åŸå› ã€
    6. å¦‚æœé€£ç›¸è¿‘æ¨è–¦ä¹Ÿç„¡æ³•æä¾›ï¼Œè«‹å›è¦†ï¼šã€Œç›®å‰æ²’æœ‰åœ¨æŒ‡å®šç¯„åœå…§æ‰¾åˆ°ç¬¦åˆã€{user_request}ã€æˆ–ç›¸è¿‘é¡å‹çš„é¤å»³ï¼Œå»ºè­°æ‚¨è€ƒæ…®æ›´å¤šå…ƒçš„é¸æ“‡ã€‚ã€
    7. ä¸è¦è™›æ§‹é¤å»³æˆ–æ¨™ç±¤ï¼Œåªèƒ½ä½¿ç”¨æ¸…å–®èˆ‡ context ä¸­æä¾›çš„è³‡è¨Šã€‚
    8. è«‹ç”¨æ¢åˆ—å¼ã€æ¸…æ¥šæ ¼å¼åŒ–æ–¹å¼è¼¸å‡ºï¼Œæ¯é–“é¤å»³åˆ†æ®µåˆ—å‡ºè³‡è¨Šã€‚

    ---

    # âœ… ä½¿ç”¨è€…è¼¸å…¥éœ€æ±‚ï¼š
    ã€Œ{user_request}ã€

    # âœ… ä»¥ä¸‹ç‚º RAG æª¢ç´¢çµæœï¼ˆä½¿ç”¨è€…éå¾€ç´€éŒ„æ¨™ç±¤ï¼Œå«æ¬Šé‡ã€é »ç‡èˆ‡æ—¥æœŸåƒè€ƒï¼‰ï¼š
    {top_context}

    # âœ… ä»¥ä¸‹ç‚ºæœ€æ–°å¯æ¨è–¦é¤å»³æ¸…å–®ï¼ˆåƒ…èƒ½å¾ä¸‹æ–¹é¤å»³æ¸…å–®é¸æ“‡ï¼‰ï¼š
    {json.dumps(restaurants, ensure_ascii=False, indent=2)}

    è«‹ç¶œåˆåƒè€ƒä¸Šè¿°è³‡è¨Šï¼Œæ¨è–¦ 3 é–“é¤å»³ï¼Œä¸¦é‡å°æ¯ä¸€é–“é¤å»³è©³ç´°èªªæ˜æ¨è–¦åŸå› ã€åƒ¹æ ¼ç¯„åœï¼Œä»¥åŠèˆ‡éå¾€åå¥½æ¨™ç±¤æˆ–éœ€æ±‚çš„é—œè¯æ€§ã€‚
    """
    ans = openai_api(system_message, user_request)
    return ans


# --------------------- å»ºç«‹ Gradio ä»‹é¢ ---------------------#
gr.close_all()
iface = gr.Interface(
    fn=gradio_app,
    inputs=[
        gr.Textbox(label="åœ°é»"),
        gr.Radio(choices=["1", "2", "3"], label="æ¨¡å¼", value="1"),
        gr.Number(label="æ‰€éœ€æœ€å°æ™‚é–“", value=10),
        gr.Textbox(label="è«‹è¼¸å…¥æ‚¨çš„è«‹æ±‚"),
        gr.Checkbox(label="æ‰‹å‹•åˆ·æ–°", value=False)
    ],
    outputs="text",
    title="é¤é»æ¨è–¦ Chatbot",
    cache_examples=False
)
iface.launch(debug=True, share=False)